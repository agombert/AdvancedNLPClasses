{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Baseline with Regexes and spaCy for Spam Detection\n",
        "\n",
        "In this notebook, we will:\n",
        "\n",
        "1. Load a spam detection dataset from Hugging Face.\n",
        "2. Split our data into **train**, **dev**, and **test** sets, and explain why we need all three.\n",
        "3. Create a **regex-based baseline pipeline**:\n",
        "   - Build naive patterns from the **train** set.\n",
        "   - Evaluate on **test** set.\n",
        "   - Check results on **dev** set to find false positives/negatives.\n",
        "   - Update regex rules.\n",
        "   - Final metrics on the **test** set.\n",
        "4. Build a **spaCy pipeline** for spam detection:\n",
        "   - Use token and phrase matchers.\n",
        "   - Repeat the same steps (train -> dev -> refine -> test).\n",
        "5. Compare results between the improved regex approach and spaCy approach."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup and Imports\n",
        "\n",
        "We’ll need:\n",
        "- **datasets**: To load the spam dataset.\n",
        "- **scikit-learn**: For splitting the dataset and computing metrics.\n",
        "- **re** (built-in): For regex-based matching.\n",
        "- **spaCy**: For token and phrase matchers.\n",
        "\n",
        "Make sure to look at this [link](https://agombert.github.io/AdvancedNLPClasses/notebooks/) to install all the dependencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# If you're in a local environment, uncomment the lines below:\n",
        "# !poetry run python -m spacy download en_core_web_sm\n",
        "\n",
        "import re\n",
        "import spacy\n",
        "from datasets import load_dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "nlp.max_length = 2000000  # in case we have large texts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load the Dataset\n",
        "\n",
        "We'll use [NotShrirang/email-spam-filter](https://huggingface.co/datasets/NotShrirang/email-spam-filter). It's a dataset with email text labeled as spam or not spam."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/113 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "train.csv:   0%|          | 0.00/5.40M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/5171 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['Unnamed: 0', 'label', 'text', 'label_num'],\n",
              "        num_rows: 5171\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset = load_dataset(\"NotShrirang/email-spam-filter\")\n",
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We expect the dataset to have a `train` split by default, which we’ll further split into **train**, **dev**, and a final **test**. Alternatively, we can keep the existing train as a larger pool and create dev/test from it. Some datasets also come with separate test sets. We'll check what's available after loading."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'Unnamed: 0': Value(dtype='int64', id=None),\n",
              " 'label': Value(dtype='string', id=None),\n",
              " 'text': Value(dtype='string', id=None),\n",
              " 'label_num': Value(dtype='int64', id=None)}"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# We'll see the columns: we expect something like {'text': ..., 'spam': ...}.\n",
        "dataset[\"train\"].features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Create Train/Dev/Test Splits\n",
        "\n",
        "**Why do we need a dev set in addition to a train/test set?**\n",
        "- **Train** set: used to fit our model (or in this case, develop our regex/spaCy patterns).\n",
        "- **Dev** (validation) set: used to **tweak** or **refine** patterns, hyperparameters, etc., without touching the final test. This prevents overfitting on the test set.\n",
        "- **Test** set: final unbiased evaluation.\n",
        "\n",
        "If we only had train/test, we might continually adjust our method to do better on the test set, inadvertently tuning to that test distribution. The dev set helps keep the test set \"truly\" unseen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "      <th>label_num</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>605</td>\n",
              "      <td>ham</td>\n",
              "      <td>Subject: enron methanol ; meter # : 988291\\nth...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2349</td>\n",
              "      <td>ham</td>\n",
              "      <td>Subject: hpl nom for january 9 , 2001\\n( see a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3624</td>\n",
              "      <td>ham</td>\n",
              "      <td>Subject: neon retreat\\nho ho ho , we ' re arou...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4685</td>\n",
              "      <td>spam</td>\n",
              "      <td>Subject: photoshop , windows , office . cheap ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2030</td>\n",
              "      <td>ham</td>\n",
              "      <td>Subject: re : indian springs\\nthis deal is to ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0 label                                               text  \\\n",
              "0         605   ham  Subject: enron methanol ; meter # : 988291\\nth...   \n",
              "1        2349   ham  Subject: hpl nom for january 9 , 2001\\n( see a...   \n",
              "2        3624   ham  Subject: neon retreat\\nho ho ho , we ' re arou...   \n",
              "3        4685  spam  Subject: photoshop , windows , office . cheap ...   \n",
              "4        2030   ham  Subject: re : indian springs\\nthis deal is to ...   \n",
              "\n",
              "   label_num  \n",
              "0          0  \n",
              "1          0  \n",
              "2          0  \n",
              "3          1  \n",
              "4          0  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_data = dataset[\"train\"].to_pandas()\n",
        "df_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train size: 3102\n",
            "Dev size:   1034\n",
            "Test size:  1035\n"
          ]
        }
      ],
      "source": [
        "# We'll do a 60/20/20 split from the single 'train' dataset.\n",
        "df_train, df_temp = train_test_split(df_data, test_size=0.4, stratify=df_data[\"label\"], random_state=42)\n",
        "df_dev, df_test = train_test_split(df_temp, test_size=0.5, stratify=df_temp[\"label\"], random_state=42)\n",
        "\n",
        "print(\"Train size:\", len(df_train))\n",
        "print(\"Dev size:  \", len(df_dev))\n",
        "print(\"Test size: \", len(df_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we have 3 separate splits. We'll define some helper functions for evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_metrics(y_true, y_pred):\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    prec = precision_score(y_true, y_pred, pos_label=1)\n",
        "    rec = recall_score(y_true, y_pred, pos_label=1)\n",
        "    f1 = f1_score(y_true, y_pred, pos_label=1)\n",
        "    return {\n",
        "        \"accuracy\": acc,\n",
        "        \"precision\": prec,\n",
        "        \"recall\": rec,\n",
        "        \"f1\": f1\n",
        "    }\n",
        "\n",
        "def print_metrics(metrics_dict, prefix=\"\"):\n",
        "    print(f\"{prefix} Accuracy:  {metrics_dict['accuracy']*100:.2f}%\")\n",
        "    print(f\"{prefix} Precision: {metrics_dict['precision']*100:.2f}%\")\n",
        "    print(f\"{prefix} Recall:    {metrics_dict['recall']*100:.2f}%\")\n",
        "    print(f\"{prefix} F1-score:  {metrics_dict['f1']*100:.2f}%\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Regex-Based Baseline\n",
        "\n",
        "### 3a. Create a first naive pipeline\n",
        "\n",
        "We’ll look at the **train set** to find some potential spam indicators. Typically, spam might have words like `free`, `win`, `urgent`, `congratulations`, etc. This is just a guess. In a real scenario, you’d examine the train data more carefully."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('the', 4778),\n",
              " ('to', 3356),\n",
              " ('and', 3123),\n",
              " ('of', 2967),\n",
              " ('a', 2402),\n",
              " ('in', 2041),\n",
              " ('you', 1744),\n",
              " ('for', 1659),\n",
              " ('this', 1519),\n",
              " ('is', 1476),\n",
              " ('your', 1246),\n",
              " ('subject', 1000),\n",
              " ('with', 939),\n",
              " ('3', 918),\n",
              " ('that', 874),\n",
              " ('or', 869),\n",
              " ('on', 850),\n",
              " ('s', 848),\n",
              " ('be', 842),\n",
              " ('as', 766)]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Let's gather some 'spammy' tokens from the train set by naive frequency analysis.\n",
        "# We'll do a quick check of most common words in spam vs. not spam.\n",
        "\n",
        "import collections\n",
        "\n",
        "spam_texts = df_train[df_train[\"label\"] == \"spam\"][\"text\"].values\n",
        "ham_texts = df_train[df_train[\"label\"] == \"ham\"][\"text\"].values\n",
        "\n",
        "def tokenize(text):\n",
        "    return re.findall(r\"\\w+\", text.lower())\n",
        "\n",
        "spam_words = []\n",
        "for txt in spam_texts:\n",
        "    spam_words.extend(tokenize(txt))\n",
        "\n",
        "spam_counter = collections.Counter(spam_words)\n",
        "spam_most_common = spam_counter.most_common(20)\n",
        "spam_most_common"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We clearly see a lot of common words in the spam emails. \"The\", \"of\", ... stop words in English. Let's get rid of them. I imagine there are a lot of numbers and punctuation as well. Let's get rid of them too."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('subject', 1000),\n",
              " ('company', 506),\n",
              " ('http', 460),\n",
              " ('information', 361),\n",
              " ('statements', 312),\n",
              " ('price', 310),\n",
              " ('email', 277),\n",
              " ('pills', 258),\n",
              " ('time', 241),\n",
              " ('font', 214),\n",
              " ('free', 211),\n",
              " ('message', 194),\n",
              " ('investment', 194),\n",
              " ('stock', 187),\n",
              " ('money', 184),\n",
              " ('business', 184),\n",
              " ('securities', 179),\n",
              " ('report', 176),\n",
              " ('2004', 174),\n",
              " ('contact', 172)]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "import string\n",
        "\n",
        "punctuation = string.punctuation\n",
        "numbers = string.digits\n",
        "\n",
        "stop_words = set(STOP_WORDS)\n",
        "\n",
        "spam_words = []\n",
        "for txt in spam_texts:\n",
        "    for word in tokenize(txt):\n",
        "        if word not in stop_words and word not in punctuation and word not in numbers and len(word) > 3:\n",
        "            spam_words.append(word)\n",
        "\n",
        "spam_counter = collections.Counter(spam_words)\n",
        "spam_most_common = spam_counter.most_common(20)\n",
        "spam_most_common"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We'll pick a few frequent tokens as naive spam triggers. (In reality, you'd do more thorough exploration or use a more advanced approach—but let's keep it simple for demonstration.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Let's define a basic regex pattern that flags emails containing typical spammy words.\n",
        "spam_keywords = [\"free\", \"http\", \"www\", \"money\", \n",
        "                 \"win\", \"winner\", \"congratulations\", \n",
        "                 \"urgent\", \"claim\", \"prize\", \"click\",\n",
        "                 \"price\"]\n",
        "pattern = re.compile(r\"(\" + \"|\".join(spam_keywords) + r\")\", re.IGNORECASE)\n",
        "\n",
        "def regex_spam_classifier(text):\n",
        "    if pattern.search(text):\n",
        "        return 1  # spam\n",
        "    return 0     # not spam"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3b. Get metrics on the **test** set\n",
        "\n",
        "Even though we said we’d refine on dev, let’s see how it does out-of-the-box on the test set. (Sometimes it’s informative to check a naive baseline right away.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Regex Baseline (Test)  Accuracy:  68.79%\n",
            "Regex Baseline (Test)  Precision: 47.42%\n",
            "Regex Baseline (Test)  Recall:    70.33%\n",
            "Regex Baseline (Test)  F1-score:  56.64%\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_test_true = df_test[\"label_num\"].values\n",
        "y_test_pred = [regex_spam_classifier(txt) for txt in df_test[\"text\"].values]\n",
        "\n",
        "test_metrics = compute_metrics(y_test_true, y_test_pred)\n",
        "print_metrics(test_metrics, prefix=\"Regex Baseline (Test) \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Okay, not so bad, we get 70% of the spam emails, but we also have a lot of false positives almost 50% of our predictions are false positives !!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3c. Check dev set, find false positives & negatives\n",
        "\n",
        "Let’s see how many spam messages were missed (false negatives) and how many ham messages were flagged as spam (false positives) on the dev set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Regex Baseline (Dev)  Accuracy:  67.41%\n",
            "Regex Baseline (Dev)  Precision: 45.77%\n",
            "Regex Baseline (Dev)  Recall:    66.67%\n",
            "Regex Baseline (Dev)  F1-score:  54.27%\n",
            "\n",
            "False Positives: 237 examples\n",
            "False Negatives: 100 examples\n"
          ]
        }
      ],
      "source": [
        "y_dev_true = df_dev[\"label_num\"].values\n",
        "texts_dev = df_dev[\"text\"].values\n",
        "\n",
        "y_dev_pred = [regex_spam_classifier(txt) for txt in texts_dev]\n",
        "dev_metrics = compute_metrics(y_dev_true, y_dev_pred)\n",
        "print_metrics(dev_metrics, prefix=\"Regex Baseline (Dev) \")\n",
        "\n",
        "# Let's identify the false positives and negatives.\n",
        "fp_indices = []  # predicted spam but actually ham\n",
        "fn_indices = []  # predicted ham but actually spam\n",
        "\n",
        "for i, (gold, pred) in enumerate(zip(y_dev_true, y_dev_pred)):\n",
        "    if gold == 0 and pred == 1:\n",
        "        fp_indices.append(i)\n",
        "    elif gold == 1 and pred == 0:\n",
        "        fn_indices.append(i)\n",
        "\n",
        "print(\"False Positives:\", len(fp_indices), \"examples\")\n",
        "print(\"False Negatives:\", len(fn_indices), \"examples\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First thing is that the metrics are quite similar from the test set. Which means that both sets may be similar. Therefore if we find a way to improve on the dev set, we should see an improvement on the test set. \n",
        "\n",
        "We clearly see that we have a lot of false positives, also a significant number of false negatives. Therefore first, we may want to cover more cases and then create some other rules to reduce the number of false positives."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3d. Analyze FN to improve regex\n",
        "\n",
        "Let's first take a look at the false negatives to see if we can improve the regex."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Some False Negatives ---\n",
            "\n",
            "DEV INDEX: 17\n",
            "Subject: fw : old aged mmomy wants a date\n",
            "hey , man ! : )\n",
            "dovizhdane\n",
            " ...\n",
            "---\n",
            "DEV INDEX: 22\n",
            "Subject: prescription medication delivered overnight . p . n . termin , valium , + xanax + available . ki 80 hzhrb 5 if\n",
            "we believe ordering medication should be as simple as ordering anything else on the internet : private , secure , and easy .\n",
            "always available : \\ xana : x : # vlagr @ , | vialium ^ ...\n",
            "---\n",
            "DEV INDEX: 30\n",
            "Subject: 6 et vi - codin le 6 ally baronial fy dmabi\n",
            "hey there ,\n",
            "ofore\n",
            "phacy\n",
            "specials on :\n",
            "viin , van - ax , vi - are\n",
            "tariff\n",
            "pleaove\n",
            "me\n",
            "taunt\n",
            "accompaniment\n",
            "yjhanl pactwmtnfbiiw pl ym romjr\n",
            "jco jbxdlnvtwszthg\n",
            "njrjduhen d yfwvg lrn ...\n",
            "---\n",
            "DEV INDEX: 44\n",
            "Subject: story - my daughter isn ' t in pain anymore\n",
            "newsweek medical : are you in pain ?\n",
            "comparison finalists\n",
            "no more\n",
            "crave persuasivehave penis worldbodyguard\n",
            "lackey coupeglutamine escape morphinefisherman\n",
            "cryptanalytic stokecellar algonquin bewitchcatnip\n",
            "complicate alkalinedalton kafkaesque gigab ...\n",
            "---\n",
            "DEV INDEX: 57\n",
            "Subject: whats the word . order your prescr - iption ' s here . . adams gettysburg\n",
            " . . . . pertinaciousd ' . . . .\n",
            "rawmnv ...\n",
            "---\n",
            "DEV INDEX: 68\n",
            "Subject: how to earn thousands writing google adwords part - time kara\n",
            "googlecash gives you all the tools you need to turn the search engine google . com into\n",
            "an autopilot cash generating machine !\n",
            "what ' s your dream lifestyle ?\n",
            "phosphor disco ghoulish eardrum airplane geriatric approximant drop co ...\n",
            "---\n",
            "DEV INDEX: 72\n",
            "Subject: microsoft update warning - january 7 th\n",
            "minnesota , which can clinch a wild - card\n",
            "playoff spot with a loss by either carolina or st . louis this weekend , appeared on\n",
            "its way to retaking the lead . but a holding penalty on birk - - the vikings were\n",
            "flagged nine times for 78 yards - - wiped ...\n",
            "---\n",
            "DEV INDEX: 77\n",
            "Subject: young pussies\n",
            "tonya could feel the glow of the hundreds of candles on her bare skin .\n",
            "her hair was plastered to her face and she thought she must have looked\n",
            "horrible soaking wet , but she didn ' t care . gabriel thought she was beautiful\n",
            "and that was all she needed to know . tonya slid tow ...\n",
            "---\n",
            "DEV INDEX: 90\n",
            "Subject: the only smart way to control spam\n",
            "hey , i have a special _ offer for you . . .\n",
            "better than all other spam filters -\n",
            "only delivers the email you want !\n",
            "this is the ultimate solution that is guaranteed to stop all spam\n",
            "without\n",
            "losing any of your important email ! this system protects you 100 ...\n",
            "---\n",
            "DEV INDEX: 108\n",
            "Subject: can jim come over and watch ?\n",
            "up to 80 %\n",
            "savings on\n",
            "xanax ,\n",
            "valium ,\n",
            "codeine ,\n",
            "viagra\n",
            "and moretry us out here\n",
            "for email\n",
            "removal ,\n",
            "go here .\n",
            "jewelry elsinore chairperson ameslan decorticate badge foam cutler zinc shopkeep cylinder oracle alcove steppe inefficacy skeleton quartic wasp compagn ...\n",
            "---\n",
            "DEV INDEX: 114\n",
            "Subject: greatly improve your stamina\n",
            "i ' ve been using your product for 4 months now . i ' ve increased my\n",
            "length from 2\n",
            "to nearly 6 . your product has saved my sex life . - matt , fl\n",
            "my girlfriend loves the results , but she doesn ' t know what i do . she\n",
            "thinks\n",
            "it ' s natural - thomas , ca\n",
            "pleasu ...\n",
            "---\n",
            "DEV INDEX: 116\n",
            "Subject: cheap soft viagra\n",
            "viagra soft tabs : perfect feeling of being men again .\n",
            "starts working within just 15 minutes .\n",
            "soft tabs :\n",
            "info site\n",
            "you take a candy and get hard rock erection .\n",
            "this is not miracle . this is just soft tabs .\n",
            "remove your email ...\n",
            "---\n",
            "DEV INDEX: 131\n",
            "Subject: penls enlarg 3 ment pllls\n",
            "enlarge your penls nowcllck h 3 re !\n",
            "no more ...\n",
            "---\n",
            "DEV INDEX: 161\n",
            "Subject: antigen downstairs dance\n",
            "still no luck enlarging it ?\n",
            "our 2 products will work for you !\n",
            "1 . # 1 supplement available ! - works !\n",
            "for vprx ciilck here\n",
            "and\n",
            "2 . * new * enhancement oil - get hard in 60 seconds ! amazing !\n",
            "like no other oil you ' ve seen .\n",
            "for vprx oil ciilck here\n",
            "the 2 produc ...\n",
            "---\n",
            "DEV INDEX: 167\n",
            "Subject: new details id : 21195\n",
            "get your u n ive\n",
            "rsi t y d i\n",
            "plom acal 1 this number : 206\n",
            "- 424 - 1596 ( anytime )\n",
            "there are no required tests , class e s , books , or\n",
            "interviews !\n",
            "get a b a chelors , masters , m ba , and d\n",
            "o ctorate ( phd ) d i\n",
            "ploma ! receive the benefits and admiration\n",
            "that come ...\n",
            "---\n",
            "DEV INDEX: 188\n",
            "Subject: welcome to toronto pharmac euticals , the net ' s most secure source for presc ription medicines made in the usa . . coincide confrere\n",
            "you can finally get * real * pain medic ation that works .\n",
            "we receive your orders and one of our 24 x 7 onboard us physicians will approve of your order ( 9 ...\n",
            "---\n",
            "DEV INDEX: 202\n",
            "Subject: inexplicable crying spells , sadness and / or irritability\n",
            "- - - - 22037566626923367\n",
            "hi varou ,\n",
            "setting small , achievable goals will help will take you farther than you can imagine over time . it will help you reach your final destination : a happier , low - anxiety life .\n",
            "we offer some of ...\n",
            "---\n",
            "DEV INDEX: 205\n",
            "Subject: quick , easy vicodin w lij tirb xhzcixu\n",
            "we are the only source for vicodin online !\n",
            "- very easy ordering\n",
            "- no prior prescription needed\n",
            "- quick delivery\n",
            "- inexpensive\n",
            " ...\n",
            "---\n",
            "DEV INDEX: 213\n",
            "Subject: super cheap rates on best sexual health drug !\n",
            "the power and effects of cialis stay in your body 9 times longer than vlagra !\n",
            "save up to 60 % - order generic cialis today !\n",
            "now they ' re chewable . like soft candy !\n",
            "excalibu snuffybeautifu roy taffy daddy birdturbo abby cookies volley prope ...\n",
            "---\n",
            "DEV INDEX: 216\n",
            "Subject: lower lipids and lower risk for heart disease langley\n",
            "some hills are never seenthe universe is\n",
            "expanding\n",
            "album : good stufftitle : bad influence call it\n",
            "bad big town holds me backbig town skinns my mind\n",
            "sorry to have troubled you ; but it couldn ' t\n",
            "be helped\n",
            "bolan kerlaugir xmo 3 reginlejf ...\n",
            "---\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n--- Some False Negatives ---\\n\")\n",
        "for idx in fn_indices[:20]:\n",
        "    print(\"DEV INDEX:\", idx)\n",
        "    print(texts_dev[idx][:300], \"...\")\n",
        "    print(\"---\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Okay looks interesting, maybe let's look for words that appear in the false negatives but not in the false positives."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "medications 1.0\n",
            "palestinian 1.0\n",
            "viagra 1.0\n",
            "cheap 1.0\n",
            "soft 1.0\n",
            "minutes 1.0\n",
            "vicodin 1.0\n",
            "cialis 1.0\n",
            "doctor 1.0\n",
            "blood 1.0\n",
            "loading 1.0\n",
            "csgu 1.0\n",
            "prescription 0.9090909090909091\n",
            "spam 0.8888888888888888\n",
            "stop 0.8888888888888888\n",
            "sources 0.875\n",
            "generic 0.8\n",
            "military 0.8\n",
            "rock 0.8\n",
            "approved 0.8\n",
            "sound 0.8\n",
            "mobile 0.7777777777777778\n",
            "ordering 0.75\n",
            "story 0.6666666666666666\n",
            "tabs 0.6666666666666666\n",
            "lady 0.6666666666666666\n",
            "video 0.625\n",
            "waiting 0.625\n",
            "remove 0.6153846153846154\n",
            "attack 0.6\n",
            "inside 0.6\n",
            "international 0.6\n",
            "friend 0.6\n",
            "street 0.6\n",
            "took 0.6\n",
            "secure 0.5714285714285714\n",
            "quick 0.5454545454545454\n",
            "turn 0.5\n",
            "clear 0.5\n",
            "hard 0.5\n",
            "real 0.5\n",
            "quality 0.5\n",
            "software 0.5\n",
            "paper 0.5\n",
            "short 0.5\n",
            "credit 0.46153846153846156\n",
            "enjoy 0.4444444444444444\n",
            "said 0.4444444444444444\n",
            "town 0.42857142857142855\n",
            "case 0.42857142857142855\n"
          ]
        }
      ],
      "source": [
        "# Let's look for words that appear a lot in the false negatives but not so much in the false positives.\n",
        "# Let's use collections to count the words in the false negatives and false positives.\n",
        "# We'll get rid of stop words, punctuation and numbers.\n",
        "\n",
        "fn_words = []\n",
        "for idx in fn_indices:\n",
        "    for word in tokenize(texts_dev[idx]):\n",
        "        if word not in stop_words and word not in punctuation and word not in numbers and len(word) > 3:\n",
        "            fn_words.append(word)\n",
        "\n",
        "fp_words = []\n",
        "for idx in fp_indices:\n",
        "    for word in tokenize(texts_dev[idx]):\n",
        "        if word not in stop_words and word not in punctuation and word not in numbers and len(word) > 3:\n",
        "            fp_words.append(word)\n",
        "\n",
        "\n",
        "fn_counter = collections.Counter(fn_words)\n",
        "fp_counter = collections.Counter(fp_words)\n",
        "\n",
        "# Let's create a ratio of occurences in the false negatives over the false positives.\n",
        "fn_ratio = {word: fn_counter.get(word, 0) / (fp_counter.get(word, 0) + fn_counter.get(word, 0)) \n",
        "            for word in fn_counter if fp_counter.get(word, 0) + fn_counter.get(word, 0) > 4}\n",
        "\n",
        "#Let's sort the words by the ratio.\n",
        "fn_ratio = sorted(fn_ratio.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "#Let's print the words that appear a lot in the false negatives but not so much in the false positives.\n",
        "for word, ratio in fn_ratio[:50]:\n",
        "    print(word, ratio)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Well looks like we have some interesting words there. Let's add them to the regex. We do it dumb way here, but in practice we should explore a bit more."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "spam_keywords = [\"free\", \"http\", \"www\", \"money\", \n",
        "                 \"win\", \"winner\", \"congratulations\", \n",
        "                 \"urgent\", \"claim\", \"prize\", \"click\",\n",
        "                 \"price\", \"viagra\", \"vialium\", \"medication\",\n",
        "                 \"aged\", \"xana\", \"xanax\", \"asyc\", \"cheap\", \n",
        "                 \"palestinian\", \"blood\", \"doctor\", \"cialis\", \n",
        "                 \"minutes\", \"vicodin\", \"soft\", \"loading\", \n",
        "                 \"csgu\", \"medications\", \"prescription\", \"spam\", \"stop\"]\n",
        "pattern = re.compile(r\"(\" + \"|\".join(spam_keywords) + r\")\", re.IGNORECASE)\n",
        "\n",
        "def regex_spam_classifier_v0_2(text):\n",
        "    if pattern.search(text):\n",
        "        return 1  # spam\n",
        "    return 0     # not spam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Regex Baseline (Test)  Accuracy:  70.14%\n",
            "Regex Baseline (Test)  Precision: 49.08%\n",
            "Regex Baseline (Test)  Recall:    80.33%\n",
            "Regex Baseline (Test)  F1-score:  60.94%\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_test_true = df_test[\"label_num\"].values\n",
        "y_test_pred = [regex_spam_classifier_v0_2(txt) for txt in df_test[\"text\"].values]\n",
        "\n",
        "test_metrics = compute_metrics(y_test_true, y_test_pred)\n",
        "print_metrics(test_metrics, prefix=\"Regex Baseline (Test) \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Incredible, meaning that just by adding a few words we get a huge improvement in the metrics (+10% of recall!) and the precision is still more or less the same.\n",
        "\n",
        "### 3e. Analyze FP to improve regex\n",
        "\n",
        "Let's do the same for the false positives. Meaning that we will find words that appear a lot in the false positives but not so much in the false negatives.\n",
        "If the message is detected as spam, we will apply another regex to check if it contains any of the words in the false positives. If it does, we will label it as ham.\n",
        "\n",
        "First let's check the dev set false positives."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Regex Baseline (Dev)  Accuracy:  70.50%\n",
            "Regex Baseline (Dev)  Precision: 49.49%\n",
            "Regex Baseline (Dev)  Recall:    81.00%\n",
            "Regex Baseline (Dev)  F1-score:  61.44%\n",
            "\n",
            "False Positives: 248 examples\n",
            "False Negatives: 57 examples\n"
          ]
        }
      ],
      "source": [
        "y_dev_true = df_dev[\"label_num\"].values\n",
        "texts_dev = df_dev[\"text\"].values\n",
        "\n",
        "y_dev_pred = [regex_spam_classifier_v0_2(txt) for txt in texts_dev]\n",
        "dev_metrics = compute_metrics(y_dev_true, y_dev_pred)\n",
        "print_metrics(dev_metrics, prefix=\"Regex Baseline (Dev) \")\n",
        "\n",
        "# Let's identify the false positives and negatives.\n",
        "fp_indices = []  # predicted spam but actually ham\n",
        "fn_indices = []  # predicted ham but actually spam\n",
        "\n",
        "for i, (gold, pred) in enumerate(zip(y_dev_true, y_dev_pred)):\n",
        "    if gold == 0 and pred == 1:\n",
        "        fp_indices.append(i)\n",
        "    elif gold == 1 and pred == 0:\n",
        "        fn_indices.append(i)\n",
        "\n",
        "print(\"False Positives:\", len(fp_indices), \"examples\")\n",
        "print(\"False Negatives:\", len(fn_indices), \"examples\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see that we reduced by two the number of false negatives. Let's see if we can reduce the number of false positives."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Some False Positives ---\n",
            "\n",
            "DEV INDEX: 1\n",
            "Subject: playgroup pictures from houston cow parade\n",
            "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = ? easy unsubscribe click here : http : / / topica . com / u / ? a 84 vnf . a 9 ivhm or send an email to : brcc . yf  ...\n",
            "---\n",
            "DEV INDEX: 2\n",
            "Subject: re : united oil & minerals , inc . , chapman unit # 1\n",
            "vance ,\n",
            "deal # 357904 has been created and entered in sitara .\n",
            "bob\n",
            "vance l taylor\n",
            "08 / 04 / 2000 04 : 06 pm\n",
            "to : robert cotten / hou / ect @ ect , hillary mack / corp / enron @ enron , lisa\n",
            "hesse / hou / ect @ ect , trisha hughes / hou / ...\n",
            "---\n",
            "DEV INDEX: 9\n",
            "Subject: re : spinnaker exploration company , l . l . c . n . padre is . block 883 l\n",
            "offshore kleberg county , texas contract 96047295 , meter 098 - 9862 ( 098 - 9848\n",
            "platform )\n",
            "thanks , bob . it now turns out that due to operational issues , the additional 10 , 000 / d may not come on next week . s ...\n",
            "---\n",
            "DEV INDEX: 12\n",
            "Subject: enronoptions update !\n",
            "enronoptions announcement\n",
            "we have updated the enronoptions \u0001 ) your stock option program web site ! the\n",
            "web site now contains specific details of the enronoptions program including\n",
            "the december 29 , 2000 grant price and additional information on employee\n",
            "eligibility .\n",
            " ...\n",
            "---\n",
            "DEV INDEX: 13\n",
            "Subject: panenergy marketing march 2000 production\n",
            "deal # 157288\n",
            "per our conversation yesterday afternoon , pls . separate the centena term deal\n",
            "from the spot deal in sitara for march 2000 production .\n",
            "also , i need to have the price for the east texas redelivery changed in\n",
            "sitara from hs index $ -  ...\n",
            "---\n",
            "DEV INDEX: 24\n",
            "Subject: re : april spot tickets\n",
            "the spot deals are in and the deal numbers are added below to the original\n",
            "notice .\n",
            "vance l taylor @ ect\n",
            "03 / 28 / 2000 01 : 40 pm\n",
            "to : tom acton / corp / enron @ enron\n",
            "cc : carlos j rodriguez / hou / ect @ ect , lisa hesse / hou / ect @ ect , susan\n",
            "smith / hou / ect ...\n",
            "---\n",
            "DEV INDEX: 26\n",
            "Subject: good friday\n",
            "fyi - the risk team will not be in the office on friday . pat is evaluating\n",
            "the situation currently , and will decide later this week . let me know if you\n",
            "have any questions or concerns .\n",
            "- - - - - - - - - - - - - - - - - - - - - - forwarded by brenda f herod / hou / ect on 04 / ...\n",
            "---\n",
            "DEV INDEX: 28\n",
            "Subject: re : hpl discrepancy\n",
            "hey clem can you help us out with this one ? what are the volumes and deal\n",
            "tickets in question for those two days and what is the location ? we\n",
            "delivered to you at centana and enerfin . didn ' t we have that famous\n",
            "hpl / tetco oba already set up to handle the small volu ...\n",
            "---\n",
            "DEV INDEX: 32\n",
            "Subject: volume feedback from unify to sitara\n",
            "fyi : the following is the unify to sitara bridge back schedule from the sitara team . unify can still send the files to sitara but sitara will not process during the \" no bridge back \" times listed . this list is in response to several inquiries to me r ...\n",
            "---\n",
            "DEV INDEX: 37\n",
            "Subject: epgt\n",
            "mike :\n",
            "i am down to the last few error messages on the epgt quick response and also looking into the external pool for who 34 in unify . about 70 % of the line items have been cleaned up .\n",
            "i need the following information from you as soon as possible .\n",
            "1 . the downstream contract numbe ...\n",
            "---\n",
            "DEV INDEX: 38\n",
            "Subject: re : tenaska iv 10 / 00\n",
            "darren ,\n",
            "the demand fee is probably the best solution . we can use it to create a\n",
            "recieivable / payable with tenaska , depending on which way the calculation goes\n",
            "each month . how are pma ' s to be handled once the fee been calculated and the\n",
            "deal put in the system ? ...\n",
            "---\n",
            "DEV INDEX: 43\n",
            "Subject: re : first delivery - cummings & walker and exxon\n",
            "vance ,\n",
            "deal # 446704 has been created and entered in sitara for cummins & walker oil\n",
            "company inc . for the period 9 / 26 / 00 - 9 / 30 / 00 .\n",
            "bob\n",
            "vance l taylor\n",
            "10 / 20 / 2000 04 : 17 pm\n",
            "to : robert cotten / hou / ect @ ect\n",
            "cc : lisa hesse  ...\n",
            "---\n",
            "DEV INDEX: 66\n",
            "Subject: fw : txu fuel deals imbalances\n",
            "daren ,\n",
            "the deals listed below are related to tufco imbalances . . . let me know if you have any objections to me entering the deals . . . o ' neal 3 - 9686\n",
            "- - - - - original message - - - - -\n",
            "from : griffin , rebecca\n",
            "sent : thursday , june 28 , 2001 9 : 58 a ...\n",
            "---\n",
            "DEV INDEX: 67\n",
            "Subject: pat - out for jury duty\n",
            "i am out of the office on monday for jury duty . in my absence , charlotte\n",
            "hawkins will be the contact for the texas desk\n",
            "logistics group . she will attend any meetings while i am out and is\n",
            "responsible for our group ( we will rotate this backup\n",
            "role among the senior ...\n",
            "---\n",
            "DEV INDEX: 69\n",
            "Subject: urgent\n",
            "ed has requested that we compile a list this morning of all parties / points which we owe gas to , in the event that we need to find a home for excess volumes today . please email me a list of any meters / contracts that you are aware of . i am compiling an interim list based upon th ...\n",
            "---\n",
            "DEV INDEX: 83\n",
            "Subject: alternative work schedule status\n",
            "as you might already know we had to reschedule our second meeting that was\n",
            "scheduled for wednesday 2 / 16 to tuesday 2 / 22 in room 3013 . lunch will be\n",
            "provided . i apologize and will avoid rescheduling our meetings in the future .\n",
            "i was encouraged by the e ...\n",
            "---\n",
            "DEV INDEX: 87\n",
            "Subject: fw : tribute to america\n",
            "regards ,\n",
            "amy brock\n",
            "hbd marketing team\n",
            "office : 281 - 988 - 2157\n",
            "cell : 713 - 702 - 6815\n",
            "- - - - - original message - - - - -\n",
            "from : rex waller\n",
            "sent : wednesday , september 12 , 2001 5 : 49 pm\n",
            "to : alfred webb ; allen hadaway ; allison boren ; amy brock ; barry willi ...\n",
            "---\n",
            "DEV INDEX: 89\n",
            "Subject: re : coastal o & g , mtr . 4179 , goliad co .\n",
            "vance ,\n",
            "julie meyers created deal # 592122 in sitara . i have edited the ticket to\n",
            "reflect the details described below :\n",
            "bob\n",
            "vance l taylor\n",
            "02 / 01 / 2001 08 : 21 am\n",
            "to : robert cotten / hou / ect @ ect\n",
            "cc : clem cernosek / hou / ect @ ect\n",
            "subje ...\n",
            "---\n",
            "DEV INDEX: 91\n",
            "Subject: april availabilities\n",
            "- - - - - - - - - - - - - - - - - - - - - - forwarded by ami chokshi / corp / enron on 03 / 22 / 2000\n",
            "03 : 40 pm - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
            "\" steve holmes \" on 03 / 22 / 2000 01 : 51 : 48 pm\n",
            "to : ,\n",
            "cc : , , ,\n",
            ", ,\n",
            ", , ,\n",
            ", , ,\n",
            ", , ,\n",
            ", , ,\n",
            "subjec ...\n",
            "---\n",
            "DEV INDEX: 94\n",
            "Subject: re : hpl delivery meter 1520\n",
            "cheryl ,\n",
            "do you have any documentation on a gas lift deal with coastal ? engage ? at\n",
            "meter 098 - 1520 ? thanks . george x 3 - 6992\n",
            "- - - - - - - - - - - - - - - - - - - - - - forwarded by george weissman / hou / ect on 04 / 19 / 2000\n",
            "06 : 48 pm - - - - - - - - - ...\n",
            "---\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n--- Some False Positives ---\\n\")\n",
        "for idx in fp_indices[:20]:\n",
        "    print(\"DEV INDEX:\", idx)\n",
        "    print(texts_dev[idx][:300], \"...\")\n",
        "    print(\"---\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "topica 1.0\n",
            "ivhm 1.0\n",
            "brcc 1.0\n",
            "dfarmer 1.0\n",
            "enron 1.0\n",
            "manage 1.0\n",
            "tago 1.0\n",
            "vance 1.0\n",
            "sitara 1.0\n",
            "cotten 1.0\n",
            "hillary 1.0\n",
            "mack 1.0\n",
            "lisa 1.0\n",
            "hesse 1.0\n",
            "trisha 1.0\n",
            "hughes 1.0\n",
            "susan 1.0\n",
            "reinhardt 1.0\n",
            "melissa 1.0\n",
            "graves 1.0\n",
            "acton 1.0\n",
            "counterparty 1.0\n",
            "meter 1.0\n",
            "volumes 1.0\n",
            "mmbtu 1.0\n",
            "september 1.0\n",
            "additionally 1.0\n",
            "tracked 1.0\n",
            "wellhead 1.0\n",
            "6353 1.0\n",
            "forwarded 1.0\n",
            "jennifer 1.0\n",
            "blay 1.0\n",
            "christy 1.0\n",
            "sweeney 1.0\n",
            "jill 1.0\n",
            "zivley 1.0\n",
            "esther 1.0\n",
            "spinnaker 1.0\n",
            "padre 1.0\n",
            "96047295 1.0\n",
            "9862 1.0\n",
            "9848 1.0\n",
            "posted 1.0\n",
            "george 1.0\n",
            "weissman 1.0\n",
            "daren 1.0\n",
            "riley 1.0\n",
            "mike 1.0\n",
            "morris 1.0\n"
          ]
        }
      ],
      "source": [
        "# Let's look for words that appear a lot in the false positives but not so much in the negatives.\n",
        "# Let's use collections to count the words in the negatives and false positives.\n",
        "# We'll get rid of stop words, punctuation and numbers.\n",
        "\n",
        "positive_indices = []\n",
        "for i, (gold, pred) in enumerate(zip(y_dev_true, y_dev_pred)):\n",
        "    if gold == 1:\n",
        "        positive_indices.append(i)\n",
        "\n",
        "\n",
        "positive_words = []\n",
        "for idx in positive_indices:\n",
        "    for word in tokenize(texts_dev[idx]):\n",
        "        if word not in stop_words and word not in punctuation and word not in numbers and len(word) > 3:\n",
        "            positive_words.append(word)\n",
        "\n",
        "fp_words = []\n",
        "for idx in fp_indices:\n",
        "    for word in tokenize(texts_dev[idx]):\n",
        "        if word not in stop_words and word not in punctuation and word not in numbers and len(word) > 3:\n",
        "            fp_words.append(word)\n",
        "\n",
        "\n",
        "fp_counter = collections.Counter(fp_words)\n",
        "positive_counter = collections.Counter(positive_words)\n",
        "\n",
        "# Let's create a ratio of occurences in the false positives over the false negatives.\n",
        "fp_ratio = {word: fp_counter.get(word, 0) / (fp_counter.get(word, 0) + positive_counter.get(word, 0)) \n",
        "            for word in fp_counter if fp_counter.get(word, 0) + positive_counter.get(word, 0) > 3}\n",
        "\n",
        "#Let's sort the words by the ratio.\n",
        "fp_ratio = sorted(fp_ratio.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "#Let's print the words that appear a lot in the false positives but not so much in the false negatives.\n",
        "for word, ratio in fp_ratio[:50]:\n",
        "    print(word, ratio)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A bit leass easy, but we can try to create a new regex that should cover the false positives. A lot of names and surnames appear there, maybe quitting them would help. And also some coporate words such as \"following\" or \"brcc\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "spam_keywords = [\"free\", \"http\", \"www\", \"money\", \n",
        "                 \"win\", \"winner\", \"congratulations\", \n",
        "                 \"urgent\", \"claim\", \"prize\", \"click\",\n",
        "                 \"price\", \"viagra\", \"vialium\", \"medication\",\n",
        "                 \"aged\", \"xana\", \"xanax\", \"asyc\", \"cheap\", \n",
        "                 \"palestinian\", \"blood\", \"doctor\", \"cialis\", \n",
        "                 \"minutes\", \"vicodin\", \"soft\", \"loading\", \n",
        "                 \"csgu\", \"medications\", \"prescription\", \"spam\", \"stop\"]\n",
        "ham_keywords = [\"hillary\", \"christy\", \"chapman\", \"susan\", \"reinhardt\",\n",
        "                \"sweeney\", \"melissa\", \"hughes\", \"lisa\", \"trisha\",\n",
        "                \"september\", \"tracked\", \"wellhead\", \"volumes\", \"meter\",\n",
        "                \"offshore\", \"county\", \"manage\", \"brcc\", \"ivmh\"]\n",
        "pattern_spam_v0_3 = re.compile(r\"(\" + \"|\".join(spam_keywords) + r\")\", re.IGNORECASE)\n",
        "pattern_ham_v0_3 = re.compile(r\"(\" + \"|\".join(ham_keywords) + r\")\", re.IGNORECASE)\n",
        "\n",
        "def regex_spam_classifier_v0_3(text):\n",
        "    if len(pattern_spam_v0_3.findall(text)) > len(pattern_ham_v0_3.findall(text)):\n",
        "        return 1  # spam\n",
        "    return 0     # not spam"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3f. Test on test set\n",
        "\n",
        "We do the final metrics on the test set now that we have a more refined approach. (Though in practice, you might do multiple dev cycles, carefully checking you’re not overfitting.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Regex Baseline (Test)  Accuracy:  80.68%\n",
            "Regex Baseline (Test)  Precision: 63.37%\n",
            "Regex Baseline (Test)  Recall:    79.00%\n",
            "Regex Baseline (Test)  F1-score:  70.33%\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_test_true = df_test[\"label_num\"].values\n",
        "y_test_pred = [regex_spam_classifier_v0_3(txt) for txt in df_test[\"text\"].values]\n",
        "\n",
        "test_metrics = compute_metrics(y_test_true, y_test_pred)\n",
        "print_metrics(test_metrics, prefix=\"Regex Baseline (Test) \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Well with we improved by 10 pts precision and 10 pts recall (almost !). Just by investigating the false positives and false negatives we can see that we are now detecting more spam and less ham. Therefore looking at the data is crucial to understanstand what the model is doing !\n",
        "\n",
        "### 3g. Limitations\n",
        "\n",
        "Clearly, a regex approach is limited. We’ll often get false positives for edge cases or false negatives for spam that doesn’t match our known keywords. Regexes can’t capture synonyms or context. That’s where an ML approach or more advanced text processing can help. But still we get 70% in F1 without any ML or advanced text processing !"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. spaCy Approach\n",
        "\n",
        "We’ll create a small spaCy pipeline using the **Matcher** or **TokenMatcher** to detect spammy patterns. This is still rule-based, but spaCy makes it easier to do **token-based** patterns or phrase matching that’s more robust than plain regex.\n",
        "\n",
        "### 4a. Token matcher\n",
        "We can define token-based patterns: e.g., if a doc has `[{'LOWER': 'free'}]` or `[{'LOWER': 'click'}, {'LOWER': 'now'}]`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spacy.matcher import Matcher\n",
        "\n",
        "matcher = Matcher(nlp.vocab)\n",
        "\n",
        "# Example token-level patterns\n",
        "pattern_free = [{\"LOWER\": \"free\"}]\n",
        "pattern_click_now = [{\"LOWER\": \"click\"}, {\"LOWER\": \"now\"}]\n",
        "pattern_urgent = [{\"LOWER\": \"urgent\"}]\n",
        "# etc.\n",
        "\n",
        "matcher.add(\"FREE\", [pattern_free])\n",
        "matcher.add(\"CLICK_NOW\", [pattern_click_now])\n",
        "matcher.add(\"URGENT\", [pattern_urgent])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4b. spaCy-based classifier\n",
        "\n",
        "We'll define a function that processes text with `nlp`, runs the matcher, and if any match is found, we label it spam. We'll refine similarly by analyzing dev set mistakes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "def spacy_matcher_spam(doc):\n",
        "    matches = matcher(doc)\n",
        "    if matches:\n",
        "        return 1  # spam\n",
        "    return 0\n",
        "\n",
        "def spacy_spam_classifier(text):\n",
        "    doc = nlp(text)\n",
        "    return spacy_matcher_spam(doc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4c. Evaluate on dev set -> refine -> evaluate on test set\n",
        "\n",
        "Let’s do it quickly, given we already know the general approach. We'll compute dev metrics, see if we can spot improvements, and finalize on test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "spaCy Baseline (Test) Accuracy:  72.95%\n",
            "spaCy Baseline (Test) Precision: 64.71%\n",
            "spaCy Baseline (Test) Recall:    14.67%\n",
            "spaCy Baseline (Test) F1-score:  23.91%\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_test_pred_spacy = [spacy_spam_classifier(t) for t in df_test[\"text\"].values]\n",
        "test_metrics_spacy = compute_metrics(y_test_true, y_test_pred_spacy)\n",
        "print_metrics(test_metrics_spacy, \"spaCy Baseline (Test)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In practice, we’d repeat the false positive/negative analysis from earlier. I'll skip it as you can do it yourself :). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Compare Regex vs. spaCy Approaches\n",
        "\n",
        "We can summarize the final test metrics side by side."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Final Comparison on Test Set ---\n",
            "\n",
            "Regex v2:\n",
            " Accuracy:  80.68%\n",
            " Precision: 63.37%\n",
            " Recall:    79.00%\n",
            " F1-score:  70.33%\n",
            "\n",
            "spaCy v2:\n",
            " Accuracy:  72.95%\n",
            " Precision: 64.71%\n",
            " Recall:    14.67%\n",
            " F1-score:  23.91%\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"--- Final Comparison on Test Set ---\\n\")\n",
        "print(\"Regex v2:\")\n",
        "print_metrics(test_metrics)\n",
        "print(\"spaCy v2:\")\n",
        "print_metrics(test_metrics_spacy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We spent different amount of time on each approach, and that's why the metrics for regexes are better. With spaCy we can do more complex patterns and that's why it's more time consuming to implement. But let's imagine we use both models to see if we can improve the metrics.\n",
        "\n",
        "To do so let's compare the false positives and false negatives of the two models on the dev set. Maybe there are some patterns that are detected by one model but not by the other one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_dev_pred_spacy = [spacy_spam_classifier(t) for t in df_dev[\"text\"].values]\n",
        "y_dev_pred_regex = [regex_spam_classifier_v0_3(t) for t in df_dev[\"text\"].values]\n",
        "\n",
        "fp_indices_spacy = []\n",
        "fn_indices_spacy = []\n",
        "\n",
        "for i, (gold, pred) in enumerate(zip(y_dev_true, y_dev_pred_spacy)):\n",
        "    if gold == 0 and pred == 1:\n",
        "        fp_indices_spacy.append(i)\n",
        "    elif gold == 1 and pred == 0:\n",
        "        fn_indices_spacy.append(i)\n",
        "\n",
        "fp_indices_regex = []\n",
        "fn_indices_regex = []\n",
        "\n",
        "for i, (gold, pred) in enumerate(zip(y_dev_true, y_dev_pred_regex)):\n",
        "    if gold == 0 and pred == 1:\n",
        "        fp_indices_regex.append(i)\n",
        "    elif gold == 1 and pred == 0:\n",
        "        fn_indices_regex.append(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's look at the intersection of the two sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Models:\t spaCy\t regex\n",
            "False Positives:\t 37 \t 146\n",
            "False Negatives:\t 267 \t 63\n",
            "Common False Positives:\t 28\n",
            "Common False Negatives:\t 63\n"
          ]
        }
      ],
      "source": [
        "common_fp = set(fp_indices_spacy) & set(fp_indices_regex)\n",
        "common_fn = set(fn_indices_spacy) & set(fn_indices_regex)\n",
        "\n",
        "print('Models:\\t spaCy\\t regex')\n",
        "print(\"False Positives:\\t\", len(fp_indices_spacy), \"\\t\", len(fp_indices_regex))\n",
        "print(\"False Negatives:\\t\", len(fn_indices_spacy), \"\\t\", len(fn_indices_regex))\n",
        "print(\"Common False Positives:\\t\", len(common_fp))\n",
        "print(\"Common False Negatives:\\t\", len(common_fn))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Therefore we see that the whole false neatives from regex are detected by spaCy. But there are less false positives from spaCy. Maybe adding the spaCy patterns to confirm false positives from regex would help. This is something you can test when you have optimized the spaCy patterns and even use a model that could learn how much weight to give to each model. Or just a statistical weight to avoid using Machine Learning models !"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "bse-nlp-DetGwK6_-py3.11",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
