# Welcome to Advanced NLP Classes

Welcome to the Advanced Natural Language Processing course taught by Professor Arnault Gombert. This website contains all the learning materials, notebooks, and resources for the course.

## About This Course

This course navigates the evolution of Natural Language Processing (NLP) from foundational techniques to advanced concepts like Large Language Models and ChatGPT. It begins with core principles such as TF-IDF and word embeddings, advancing through deep learning innovations like LSTM and BERT.

The course is structured into three main parts:
1. Good old fashioned NLP (Sessions 1-4)
2. Almost part of good old fashioned NLP (Sessions 5-8)
3. LLMs, Agents & Others (Sessions 9 & 10)

## Getting Started

- Visit the [Introduction to the class](chapter1/README.md) section to learn about course objectives, structure, and requirements.
- Check the [Notebooks](notebooks.md) section for practical exercises and assignments.
- Explore the [Resources](resources.md) section for recommended readings and materials.

## Prerequisites

To get the most out of this course, you should have a good understanding of:
- Python programming
- Econometrics
- Machine learning fundamentals

### Overview and objectives

Text is complex data which is often available in abundance inside firms and public organizations. This course navigates the evolution of Natural Language Processing (NLP) from foundational techniques to advanced concepts like Large Language Models and ChatGPT.

It begins with core principles such as TF-IDF and word embeddings, advancing through deep learning innovations like LSTM and BERT. It emphasizes practical application, allowing students to build and evaluate NLP pipelines.

Key topics include transformers, few-shot and transfer learning, and ethical considerations in NLP. The course culminates in exploring cutting-edge developments, offering hands-on experience with modern NLP challenges. Its goal is to equip students with the skills to analyze and apply NLP technologies effectively and ethically in real-world scenarios.

## Course outline

### Part 1: Good old fashioned NLP (Sessions 1-4)

#### Baselines and Sparse representations (Session 1)

- Baseline & Evaluations
- TF-IDF and improvements

#### 2015 Deep learning (Session 2)

- Backpropagation in Neural Network
- LSTM, attention processes & Language Models

#### Word Embeddings (Sessions 3)

- Static word embedding (Word2Vec, GloVe, FastText…)
- Contextual embeddings (ELMo, BERT…)

#### Practical Session (Session 4)

- Baseline pipeline & Metrics evaluation
- LSTM-pipeline
- Word embedding add-ons
- Training our own embeddings

### Part 2: Almost part of good old fashioned NLP (Sessions 5-8)

#### Transformers & BERT (Session 5)

- Transformer intuition: the architecture, the self-attention layers, comparisons with recurrent neural networks
- BERT architecture: the revolution of Large Language Models

#### Few shot learning, Transfer learning (Session 6)

- Language Models are few shot learners: fine-tuning BERT architecture to transfer learning on downstream task
- Leveraging existing knowledge: using prompts to generate labels

#### Injustice & biases in NLP: detecting and mitigating (Session 7)

- Are Large Language Models stochastic parrots? Are Large Language Models useful for everyone?
- Detect and mitigate biases of Large Language Models

#### Practical Session (Session 8)

- Fine-tuning a BERT model
- How much data to get the best results?
- Low ressource? No problem
- Detecting biases

### Part 3: LLMs, Agents & Others (Sessions 9 & 10)

#### Prompt engineering & Fine-tuning

- Zero shot learning, Chain of thoughts and format the outputs
- Fine-tuning

#### Hallucinations & Introduction to Agents

- Detect hallucinations
- Other limitations
- Introduction to Agentic framework

## Required activities

Students will be required to conduct a couple of independent homeworks. This will include fine-tuning their own NLP model, assessing some models on some benchmark and proposing improvement.

Students will form teams of up to 4 students to develop their own text NLP project in which they will be asked to transfer the knowledge they have gained in class to solve a specific NLP problem.

## Evaluation

- Class Participation: 10%
- Homework: 20%
- Term project and presentation: 70%
