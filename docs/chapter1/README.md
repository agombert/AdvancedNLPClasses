# Introduction to the Class

## Professor

Arnault Gombert

## Prerequisites to enroll

Python programming, econometrics and machine learning.

## Introduction to Text Mining and Natural Language Processing

### Overview and objectives

Text is complex data which is often available in abundance inside firms and public organizations. This course navigates the evolution of Natural Language Processing (NLP) from foundational techniques to advanced concepts like Large Language Models and ChatGPT.

It begins with core principles such as TF-IDF and word embeddings, advancing through deep learning innovations like LSTM and BERT. It emphasizes practical application, allowing students to build and evaluate NLP pipelines.

Key topics include transformers, few-shot and transfer learning, and ethical considerations in NLP. The course culminates in exploring cutting-edge developments, offering hands-on experience with modern NLP challenges. Its goal is to equip students with the skills to analyze and apply NLP technologies effectively and ethically in real-world scenarios.

## Session 1: Baselines and Sparse Representations

This introductory session establishes the foundations of Natural Language Processing, focusing on traditional approaches and baseline techniques that serve as important benchmarks for more advanced methods.

### Learning Objectives

- Understand the fundamental challenges of processing natural language
- Learn about text representation using sparse vectors
- Explore baseline methods for common NLP tasks
- Develop skills in evaluating NLP model performance
- Gain practical experience implementing basic NLP pipelines

### Topics Covered

#### Baseline & Evaluations

- Introduction to NLP tasks and challenges
- Text preprocessing techniques
- Tokenization, stemming, and lemmatization
- Bag-of-words and n-gram models
- Evaluation metrics for different NLP tasks
- Establishing strong baselines for model comparison
- Cross-validation and statistical significance testing

#### TF-IDF and Improvements

- Term Frequency-Inverse Document Frequency (TF-IDF)
- Vector Space Model for document representation
- Cosine similarity and other similarity measures
- Sparse matrix representations
- Dimensionality reduction techniques
- Improvements to basic TF-IDF
- Applications in information retrieval and text classification

### Recommended Reading

- Van Rijsbergen, C. J. (1979). Information Retrieval (2nd ed.). Butterworth-Heinemann.
- Gupta et al. (2014) "Improved pattern learning for bootstrapped entity extraction"
- Wang et al. (2019) "GLUE: A Multi-Task Benchmark And Analysis Platform For Natural Language Understanding"

### Practical Components

- Implementing a basic text preprocessing pipeline
- Building a TF-IDF vectorizer from scratch
- Document similarity calculation using sparse representations
- Simple text classification using traditional machine learning algorithms
- Evaluating baseline models against benchmark datasets
