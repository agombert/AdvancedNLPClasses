# Agents

## Session 10: LLM-powered Agents and Advanced Applications

This final session explores the frontier of NLP research and applications, focusing on LLM-powered agents, hallucination detection, and emerging capabilities of language models.

### Learning Objectives

- Understand the concept of LLM-powered agents and their applications
- Learn techniques for detecting and mitigating hallucinations in LLMs
- Explore the limitations of current language models
- Gain insights into the future directions of NLP research
- Develop a critical perspective on the capabilities and limitations of language technologies

### Topics Covered

#### Hallucinations & Limitations

- Understanding hallucinations in language models
- Methods for detecting factual inconsistencies
- Self-consistency and ensemble approaches
- Retrieval-augmented generation for factuality
- Other limitations of current LLMs
- Evaluation frameworks for model reliability
- Strategies for mitigating hallucinations in applications

#### Introduction to Agentic Frameworks

- Conceptual foundations of LLM-powered agents
- ReAct: Synergizing reasoning and acting in Language Models
- Tool use and function calling capabilities
- Planning and decomposition of complex tasks
- Multi-agent systems and collaborative problem-solving
- Memory and context management in long-running agents
- Evaluation and benchmarking of agent capabilities

#### Emerging Research Directions

- World models and their role in language understanding
- Smaller, more efficient models vs. scaling trends
- Multimodal and embodied language understanding
- Alignment and safety considerations
- Interpretability and explainability research
- Computational efficiency and environmental impact

### Recommended Reading

- Yao et al. (2023) "ReAct: Synergizing reasoning and acting in Language Models"
- Manakul et al. (2023) "SelfCheckGPT: Zero-Resource Black-Box Hallucination Detection for Generative Large Language Models"
- Weng (2024) "Extrinsic Hallucinations in LLMs"
- Mitchell (2025) "LLMs and World Models"
- Vafa et al. (2024) "Evaluating the World Model Implicit in a Generative Model"
- Feng et al. (2024) "Were RNNs All We Needed?"
- Huyen (2025) "AI Engineering"
- Warner et al. (2024) "Smarter, Better, Faster, Longer: A Modern Bidirectional Encoder for Fast, Memory Efficient, and Long Context Fine Tuning and Inference"

### Practical Components

- Building a simple LLM-powered agent with tool-use capabilities
- Implementing hallucination detection mechanisms
- Designing evaluation frameworks for agent performance
- Case studies of successful agent applications
- Group discussion on the future of NLP and language agents
- Final project presentations and feedback
