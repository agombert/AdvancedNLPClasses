{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üì∞ Real-Time Retrieval with LLMs and Tools\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this notebook, we‚Äôll explore how to **combine Large Language Models (LLMs)** like **GPT-4o** with **real-time search tools** to answer questions about the **latest news**.  \n",
    "This approach‚Äî**Retrieval-Augmented Generation (RAG)**‚Äîenhances LLMs‚Äô knowledge by integrating **live, external data**.\n",
    "\n",
    "### üìö What We‚Äôll Do\n",
    "\n",
    "- üîç Compare answers from:\n",
    "  - üß† **LLM-Only** (no external data),\n",
    "  - üåê **LLM + Tools** (using a search engine to get the latest headlines).\n",
    "- üîé Observe how **real-time search** adds relevance, accuracy, and specificity to LLM outputs.\n",
    "\n",
    "### üõ†Ô∏è Tools\n",
    "\n",
    "We‚Äôll use:\n",
    "- **GPT-4o** (to generate summaries and synthesize information),\n",
    "- **`search` tool** (to retrieve real-time headlines),\n",
    "- (optional) other tools like **Wikipedia summarization** for additional context.\n",
    "\n",
    "### üéØ Use Case: News Headlines\n",
    "\n",
    "We‚Äôll focus on a **real-world application**:  \n",
    "> üî¥ **Generating a weekly global news digest**  \n",
    "This shows how an LLM‚Äôs output can change dramatically depending on whether it uses **static knowledge** or **live data**.\n",
    "\n",
    "### üß™ Key Objectives\n",
    "\n",
    "1Ô∏è‚É£ See how **tools boost LLM answers** in **real-world news tracking**.  \n",
    "2Ô∏è‚É£ Compare **specificity, accuracy, and freshness** of LLM-Only vs. LLM+Tools answers.  \n",
    "3Ô∏è‚É£ Explore how this impacts downstream tasks like:\n",
    "- Summarization\n",
    "- Decision-making\n",
    "- Research\n",
    "\n",
    "---\n",
    "\n",
    "## üìù LLM-Only Headline Generation (Function Calling)\n",
    "\n",
    "Let‚Äôs first use the **LLM alone** to generate ‚Äúcurrent headlines‚Äù using **function calling**.  \n",
    "The key here is to see how the LLM tries to ‚Äúimagine‚Äù headlines **without access to real-time data** (‚ö†Ô∏è usually based on its training data up to 2023-2024).\n",
    "\n",
    "We‚Äôll define a simple function schema and call it via GPT-4o to **mimic** real-time headline generation.\n",
    "\n",
    "### üß© Function Schema: `generate_headlines`\n",
    "\n",
    "To make the process of **retrieving and verifying real-time news headlines** more structured, we define a **function schema** for the LLM. This schema explicitly tells the model:\n",
    "\n",
    "- What the function is called.\n",
    "- What data **structure** (JSON) it should **return**.\n",
    "\n",
    "Here‚Äôs what each field means:\n",
    "\n",
    "| Field         | Type         | Description                                                                              |\n",
    "|---------------|--------------|------------------------------------------------------------------------------------------|\n",
    "| `headlines`   | `array`      | **List of top news headlines**. These should be clear, concise, and fact-based.          |\n",
    "| `newspapers`  | `array`      | **List of news outlets** or media organizations from which the headlines are sourced.     |\n",
    "| `sources`     | `array`      | **List of URLs** (web links) for each headline, ensuring transparency and traceability.   |\n",
    "| `highlights`  | `array`      | **Three-sentence summary** that synthesizes the main points or themes from the headlines. |\n",
    "\n",
    "This structured approach ensures:\n",
    "- The LLM‚Äôs output is **consistent** and **verifiable**.\n",
    "- We can directly compare and **evaluate** the LLM‚Äôs performance.\n",
    "- Each **function call** becomes a **modular, reusable component** for future pipelines.\n",
    "\n",
    "Let‚Äôs now see how we **invoke** this function within the LLM API call ‚Äî and then move on to how **tools** (like Google Search) can complement and improve the factual accuracy of the generated headlines!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì∞ LLM-Generated Headlines (no real-time data):\n",
      "1. Governments Urge Public Calm Amid Growing Middle-East Tensions\n",
      "Source: http://newswebsite.com/middle-east-tensions\n",
      "Newspaper: None\n",
      "Highlight: Tensions continue to rise in the Middle East as governments call for calm and diplomatic solutions.\n",
      "--------------------------------\n",
      "2. Major Advances in AI Technology Announced by Leading Tech Firms\n",
      "Source: http://technews.com/ai-advances\n",
      "Newspaper: None\n",
      "Highlight: Leading technology firms unveil significant AI innovations, promising cutting-edge applications across industries.\n",
      "--------------------------------\n",
      "3. Historic Climate Agreement Reached at Global Summit\n",
      "Source: http://climatesummit.org/agreement\n",
      "Newspaper: None\n",
      "Highlight: A landmark climate agreement is reached at the global summit, signaling hope for environmental action.\n",
      "--------------------------------\n",
      "4. Unexpected Surge in Global Markets Leaves Analysts Stunned\n",
      "Source: http://financenews.com/global-markets-surge\n",
      "Newspaper: None\n",
      "Highlight: None\n",
      "--------------------------------\n",
      "5. Breakthrough in Cancer Research Offers New Hope to Patients\n",
      "Source: http://medicalbreakthroughs.com/cancer-research\n",
      "Newspaper: None\n",
      "Highlight: None\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "# Initialize the client\n",
    "client = OpenAI()\n",
    "\n",
    "function_schema = [\n",
    "    {\n",
    "        \"name\": \"generate_headlines\",\n",
    "        \"description\": \"Generate top headlines of the week\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"headlines\": {\n",
    "                    \"type\": \"array\",\n",
    "                    \"items\": {\"type\": \"string\"},\n",
    "                    \"description\": \"List of top news headlines\"\n",
    "                },\n",
    "                \"newspapers\": {\n",
    "                    \"type\": \"array\",\n",
    "                    \"items\": {\"type\": \"string\"},\n",
    "                    \"description\": \"List of news papers where the headlines were taken from\"\n",
    "                },\n",
    "                \"sources\": {\n",
    "                    \"type\": \"array\",\n",
    "                    \"items\": {\"type\": \"string\"},\n",
    "                    \"description\": \"List of URLs the headlines\"\n",
    "                },\n",
    "                \"highlights\": {\n",
    "                    \"type\": \"array\",\n",
    "                    \"items\": {\"type\": \"string\"},\n",
    "                    \"description\": \"three sentences that summarize the headlines\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"headlines\", \"sources\"]\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "# Make a function call to generate headlines\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant that generates news headlines.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Make me a list of the top 5 headlines of the week with background context\"}\n",
    "    ],\n",
    "    functions=function_schema,\n",
    "    function_call={\"name\": \"generate_headlines\"}\n",
    ")\n",
    "\n",
    "# Extract the LLM‚Äôs generated headlines\n",
    "headlines = response.choices[0].message.function_call.arguments\n",
    "headlines_json = json.loads(headlines)\n",
    "print(\"üì∞ LLM-Generated Headlines (no real-time data):\")\n",
    "headlines = headlines_json.get(\"headlines\", [])\n",
    "sources = headlines_json.get(\"sources\", [])\n",
    "newspapers = headlines_json.get(\"newspapers\", [])\n",
    "highlights = headlines_json.get(\"highlights\", [])\n",
    "\n",
    "for i, headline in enumerate(headlines):\n",
    "    print(f\"{i+1}. {headline}\")\n",
    "    try:\n",
    "        print(f\"Source: {sources[i]}\")\n",
    "    except:\n",
    "        print(\"Source: None\")\n",
    "    try:\n",
    "        print(f\"Newspaper: {newspapers[i]}\")\n",
    "    except:\n",
    "        print(\"Newspaper: None\")\n",
    "    try:\n",
    "        print(f\"Highlight: {highlights[i]}\")\n",
    "    except:\n",
    "        print(\"Highlight: None\")\n",
    "    print(\"--------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Observations\n",
    "\n",
    "‚úÖ **General Plausibility**  \n",
    "The headlines generated **sound** very plausible and realistic! They are **general** and cover common themes:\n",
    "\n",
    "* Economy/Markets  \n",
    "* International Peace  \n",
    "* Medical breakthroughs  \n",
    "* Climate action  \n",
    "* Tech innovation  \n",
    "\n",
    "‚úÖ **Diversity**  \n",
    "There‚Äôs a good **variety** in topics: economy, global politics, health, climate, and technology ‚Äî covering typical news beats.\n",
    "\n",
    "‚úÖ **Formatting & Structure**  \n",
    "The LLM even added:\n",
    "\n",
    "* **Source URLs** (likely hallucinated, not real!)  \n",
    "* **Newspaper names** (missing in this case, but often seen)  \n",
    "* **Highlight summaries**  \n",
    "\n",
    "This **looks** like real news output ‚Äî very **convincing** on first glance.\n",
    "\n",
    "### Main Limitations\n",
    "\n",
    "‚ö†Ô∏è **Key Limitations**  \n",
    "üî¥ **Not Real-Time**  \n",
    "These headlines are **not grounded** in actual real-world data. They‚Äôre ‚Äúimagined‚Äù by the LLM based on its training data (cutoff in 2023-2024).\n",
    "\n",
    "üî¥ **Hallucination**  \n",
    "* The **sources/URLs** are **hallucinated** ‚Äì not real links.  \n",
    "* **No real verification** ‚Äì it‚Äôs a guess!\n",
    "\n",
    "üî¥ **Potential Mismatch**  \n",
    "If we ask for **current** or **real** headlines, the LLM‚Äôs output **doesn‚Äôt meet the user‚Äôs real needs**.\n",
    "\n",
    "### üìù **Conclusion**\n",
    "\n",
    "This is a great **teachable moment**:\n",
    "\n",
    "* Even with function calling, LLMs can produce **convincing** and **structured** content.  \n",
    "* But **without real-time search**, they cannot provide **grounded, current** information.  \n",
    "* Next step: üîé Show how using a **search engine tool** (like Google Search API) can **fix this**!\n",
    "\n",
    "Let‚Äôs proceed to integrating **Google Search API** to **retrieve real headlines** and compare the outputs! üöÄ\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## üîé Real-Time Information Retrieval: Google Search & Wikipedia APIs\n",
    "\n",
    "In this section, we‚Äôll **bridge the gap** left by LLMs alone by using **external APIs** to gather real, up-to-date information!\n",
    "\n",
    "### üåê **1Ô∏è‚É£ DuckDuckGo-Search**\n",
    "\n",
    "üîç **What is DuckDuckGo-Search?**  \n",
    "It‚Äôs a **lightweight Python library** that uses DuckDuckGo‚Äôs public search endpoints to **retrieve real-time search results** ‚Äî no scraping needed!\n",
    "\n",
    "‚úÖ **Why use it?**  \n",
    "- No API key required!  \n",
    "- Fast and free to use for small-scale, low-volume queries.  \n",
    "- Returns search results with **titles, snippets, and URLs** ‚Äî perfect for grounding your LLM output.\n",
    "\n",
    "‚ö†Ô∏è **Limitations**  \n",
    "- Limited to 10‚Äì30 results by default.  \n",
    "- May not have the full scope of Google, but **very easy to use**.\n",
    "\n",
    "### üìö **2Ô∏è‚É£ Wikipedia API**\n",
    "\n",
    "üîç **What is the Wikipedia Library?**\n",
    "It‚Äôs a Python wrapper for the Wikipedia API, allowing easy retrieval of summaries and page content.\n",
    "\n",
    "‚úÖ **Why use it?**\n",
    "\n",
    "* Provide **factual context** and quick background on any topic.\n",
    "* No API key needed ‚Äî **open source**!\n",
    "\n",
    "‚ö†Ô∏è **Limitations**\n",
    "\n",
    "* Not always up-to-date like live news.\n",
    "* Best for **foundational knowledge**.\n",
    "\n",
    "### üöÄ Let‚Äôs see them in action!\n",
    "\n",
    "* **Google Search API** to get the latest **headlines**.\n",
    "* **Wikipedia API** to provide a short **contextual summary**.\n",
    "\n",
    "We‚Äôll compare these real-time results to the **LLM-only output** to see the difference!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from duckduckgo_search import DDGS\n",
    "\n",
    "# Country codes for different regions\n",
    "COUNTRY_CODES = {\n",
    "    'UK': 'uk-en',      # United Kingdom\n",
    "    'FR': 'fr-fr',      # France  \n",
    "    'ES': 'es-es',      # Spain\n",
    "    'DE': 'de-de',      # Germany (standard)\n",
    "    'GLOBAL': 'wt-wt'   # Worldwide\n",
    "}\n",
    "\n",
    "def ddg_news_search(query, country='GLOBAL', num_results=5, time_period='w'):\n",
    "    \"\"\"\n",
    "    Search news using DuckDuckGo with country and time filtering\n",
    "    \n",
    "    Args:\n",
    "        query (str): Search keywords\n",
    "        country (str): Country code - 'UK', 'FR', 'ES', 'GE'/'DE', 'US', or 'GLOBAL'\n",
    "        num_results (int): Maximum number of results to return\n",
    "        time_period (str): Time filter - 'd' (day), 'w' (week), 'm' (month), None (all time)\n",
    "    \n",
    "    Returns:\n",
    "        List of dictionaries with news articles including title, body, url, date, image, source\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get region code\n",
    "        region = COUNTRY_CODES.get(country.upper(), 'wt-wt')\n",
    "        \n",
    "        with DDGS() as ddgs:\n",
    "            results = []\n",
    "            \n",
    "            # Use the news search with specified parameters\n",
    "            news_results = ddgs.news(\n",
    "                keywords=query,\n",
    "                region=region,\n",
    "                timelimit=time_period,\n",
    "                max_results=num_results\n",
    "            )\n",
    "            \n",
    "            for article in news_results:\n",
    "                results.append({\n",
    "                    'title': article.get('title', ''),\n",
    "                    'body': article.get('body', ''),\n",
    "                    'url': article.get('url', ''),\n",
    "                    'date': article.get('date', ''),\n",
    "                    'image': article.get('image', ''),\n",
    "                    'source': article.get('source', ''),\n",
    "                    'country_searched': country.upper(),\n",
    "                    'region_code': region\n",
    "                })\n",
    "            \n",
    "            return results\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error performing news search: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîé DuckDuckGo Search Results:\n",
      "üîç Result 1: Where to watch Roland-Garros 2025 today for free\n",
      "URL: https://www.mlive.com/tv/2025/05/where-to-watch-roland-garros-2025-today-for-free.html\n",
      "Snippet: Italy's Matteo Gigante casts his shadow on the court as he serves against Ben Shelton of the U.S.during their third round match of the French Tennis Open, at the Roland-Garros stadium, in Paris, Friday, May 30, 2025. (AP Photo/Thibault Camus) AP\n",
      "\n",
      "üîç Result 2: 2025 French Open brackets: Latest schedule, results from Roland Garros\n",
      "URL: https://www.msn.com/en-us/sports/tennis/2025-french-open-brackets-latest-schedule-results-from-roland-garros/ar-AA1FOS22\n",
      "Snippet: Here are the latest results and schedule for the 2025 French Open: For a full list of results, visit the Roland-Garros 2025 tournament site. No. 6 Novak Djokovic (Serbia) vs. Filip Misolic (Austria) No. 3 Alexander Zverev (Germany) vs. Flavio Cobolli (Italy) No. 1 Jannik Sinner (Italy) vs. Jiri Lehecka (Czech Republic)\n",
      "\n",
      "üîç Result 3: French Open results 2025: Updated scores, bracket, seeds for men's and women's tennis singles at Roland-Garros\n",
      "URL: https://www.msn.com/en-ca/sports/other/french-open-results-2025-updated-scores-bracket-seeds-for-mens-and-womens-tennis-singles-at-roland-garros/ar-AA1FqNWP\n",
      "Snippet: Men's seedsSeedingPlayer1Jannik Sinner2Carlos Alcaraz3Alexander Zverev4Taylor Fritz5Jack Draper6Novak Djokovic7Casper Ruud8Lorenzo Musetti9Alex de Minaur10Holger Rune11Daniil Medvedev12Tommy Paul13Ben Shelton14Arthur Fils15Frances Tiafoe16Grigor Dimitrov17Andrey Rublev18Francisco Cerundolo19Jakub Mensik20Stefanos Tsitsipas21Tomas Machac22Ugo Humbert23Sebastian Korda24Karen Khachanov25Alexei¬†Popyrin26Alejandro Davidovich Fokina27Denis Shapovalov28Brandon Nakashima29Felix Auger-Aliassime30Hubert Hurkacz31Giovanni Mpetshi Perricard32Alex Michelsen2025 French Open men's first-round drawEach match in the men's draw is handled in best of five sets.\n",
      "\n",
      "üîç Result 4: Carlos Alcaraz Talks 'Difficult' French Open Win vs. Damir Dzumhur at Roland-Garros\n",
      "URL: https://bleacherreport.com/articles/25200716-carlos-alcaraz-talks-difficult-french-open-win-vs-damir-dzumhur-roland-garros\n",
      "Snippet: Carlos Alcaraz said he \"suffered quite a lot\" during his third-round win over Damir Dzumhur during the 2025 French Open in Paris.\n",
      "\n",
      "üîç Result 5: French Open 2025 Saturday Schedule and Predictions for Roland-Garros Bracket\n",
      "URL: https://bleacherreport.com/articles/25200591-french-open-2025-saturday-schedule-and-predictions-roland-garros-bracket\n",
      "Snippet: From full schedules to predictions, everything you need is below. TNT will broadcast live from Roland-Garros starting at 5 a.m. ET. There will also be whip-around coverage on truTV at the same time, while all courts will stream live on Max.\n",
      "\n",
      "üìö Wikipedia Context:\n",
      "The French Open (French: Internationaux de France de tennis), also known as Roland-Garros (French: [ Å…îl…ëÃÉ …°a Åos]), is a tennis tournament organized by the French Tennis Federation annually at Stade Roland Garros in Paris, France. It is chronologically the second of the four Grand Slam tennis events every year, held after the Australian Open and before Wimbledon and the US Open.\n",
      "The French Open begins in late May and continues for two weeks. The tournament and venue are named after the French aviator Roland Garros.\n",
      "The French Open is the premier clay court championship in the world and the only Grand Slam tournament currently held on this surface. Until 1975, the French Open was the only major tournament not played on grass. Between the seven rounds needed for a championship, the clay surface characteristics (slower pace, higher bounce), and the best-of-five-set men's singles matches, the French Open is widely regarded as the most physically demanding tournament in tennis.\n",
      "\n",
      "\n",
      "== History ==\n",
      "Officially named in French Internationaux de France de Tennis (\"French Internationals of Tennis\" in English), the tournament uses the name Roland-Garros in all languages, and it is usually called the French Open in English.\n",
      "In 1891, the Championnat de France, which is commonly referred to in English as the French Championships, began. This was only open to tennis players who were members of French clubs.\n"
     ]
    }
   ],
   "source": [
    "import wikipedia\n",
    "\n",
    "def get_wikipedia_summary(query):\n",
    "    try:\n",
    "        summary = wikipedia.summary(query, sentences=10)\n",
    "        return summary\n",
    "    except wikipedia.exceptions.DisambiguationError as e:\n",
    "        return f\"Disambiguation page: {e.options[:5]}\"\n",
    "    except wikipedia.exceptions.PageError:\n",
    "        return \"No page found.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# üîç Example search & context\n",
    "query = \"Rolland Garros Results\"\n",
    "search_results = ddg_news_search(query, country='GLOBAL', num_results=5, time_period='w')\n",
    "wiki_context = get_wikipedia_summary(query)\n",
    "\n",
    "print(\"üîé DuckDuckGo Search Results:\")\n",
    "for idx, result in enumerate(search_results, 1):\n",
    "    print(f\"üîç Result {idx}: {result.get('title')}\")\n",
    "    print(f\"URL: {result.get('url')}\")\n",
    "    print(f\"Snippet: {result.get('body')}\\n\")\n",
    "\n",
    "print(\"üìö Wikipedia Context:\")\n",
    "print(wiki_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üåéüîé News Round-Up with **LLM + Tools**\n",
    "\n",
    "So far, we‚Äôve seen how to:\n",
    "\n",
    "‚úÖ Use an **LLM (GPT-4o)** to **generate plausible headlines** (no real-time grounding).  \n",
    "‚úÖ Use **`duckduckgo-search`** and **Wikipedia** to gather **current** and **contextual** information.  \n",
    "\n",
    "### üîç **Next Step: LLMs with Tool Calling**\n",
    "\n",
    "Instead of having us manually **call each search function**, let‚Äôs **empower** the LLM to:\n",
    "\n",
    "1Ô∏è‚É£ Accept a **high-level user query** (e.g. ‚ÄúGive me a news round-up for France this week‚Äù),  \n",
    "2Ô∏è‚É£ **Call the right tools** (`ddg_news_search`, `get_wikipedia_summary`),  \n",
    "3Ô∏è‚É£ **Integrate** these real-time and contextual data,  \n",
    "4Ô∏è‚É£ **Generate** a polished, structured news round-up ‚Äî **grounded in real search results!**\n",
    "\n",
    "This illustrates:\n",
    "\n",
    "üî¥ **LLM-only** = **creative** but **not real-time**  \n",
    "üü¢ **LLM + Tools** = **current, factual, and more reliable**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß LLM is calling tools...\n",
      "   üìû Calling get_news with args: {'query': 'AI development', 'country': 'FR', 'time_period': 'm'}\n",
      "   üìû Calling get_context with args: {'query': 'AI development in France'}\n"
     ]
    }
   ],
   "source": [
    "news_tool = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"get_news\",\n",
    "        \"description\": \"Search current news with DuckDuckGo. Returns latest news headlines for a topic.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"query\": {\"type\": \"string\", \"description\": \"Search query/topic.\"},\n",
    "                \"country\": {\"type\": \"string\", \"description\": \"Country code (e.g. 'UK', 'FR', 'GLOBAL').\"},\n",
    "                \"time_period\": {\"type\": \"string\", \"description\": \"Time period for news (e.g. 'w' for week, 'm' for month).\"}\n",
    "            },\n",
    "            \"required\": [\"query\", \"country\", \"time_period\"]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "context_tool = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"get_context\",\n",
    "        \"description\": \"Fetch a Wikipedia summary for a topic.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"query\": {\"type\": \"string\", \"description\": \"Topic to look up in Wikipedia.\"}\n",
    "            },\n",
    "            \"required\": [\"query\"]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# üß∞ Tool functions (reusing yours)\n",
    "def get_news(query, country, time_period):\n",
    "    return ddg_news_search(query, country, num_results=20, time_period=time_period)\n",
    "\n",
    "def get_context(query):\n",
    "    return get_wikipedia_summary(query)\n",
    "\n",
    "# ü™Ñ Register the tools\n",
    "tools = [news_tool, context_tool]\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": (\n",
    "            \"Can you tell me what's happening about AI development in France this month? \"\n",
    "            \"And provide some context if needed. Please provide the source of the information with the url.\"\n",
    "        )\n",
    "    }\n",
    "]\n",
    "\n",
    "# ü™Ñ Let the LLM decide which tool(s) to call!\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\"  # Let LLM decide if/what to call!\n",
    ")\n",
    "\n",
    "response_message = response.choices[0].message\n",
    "\n",
    "if response_message.tool_calls:\n",
    "    print(\"üîß LLM is calling tools...\")\n",
    "    \n",
    "    # Execute each tool call\n",
    "    for tool_call in response_message.tool_calls:\n",
    "        function_name = tool_call.function.name\n",
    "        function_args = json.loads(tool_call.function.arguments)\n",
    "        \n",
    "        print(f\"   üìû Calling {function_name} with args: {function_args}\")\n",
    "        \n",
    "        # Execute the appropriate function\n",
    "        if function_name == \"get_news\":\n",
    "            function_result = get_news(\n",
    "                query=function_args[\"query\"],\n",
    "                country=function_args[\"country\"], \n",
    "                time_period=function_args[\"time_period\"]\n",
    "            )\n",
    "        elif function_name == \"get_context\":\n",
    "            function_result = get_context(\n",
    "                query=function_args[\"query\"]\n",
    "            )\n",
    "        else:\n",
    "            function_result = f\"Unknown function: {function_name}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ö°Ô∏è What the LLM Decided to Do\n",
    "\n",
    "‚úÖ **Tool Calls:**\n",
    "\n",
    "* **First**, it called the `get_news` tool with:\n",
    "\n",
    "  * `query=\"AI development\"`\n",
    "  * `country=\"FR\"`\n",
    "  * `time_period=\"m\"`\n",
    "* **Then**, it called the `get_context` tool with:\n",
    "\n",
    "  * `query=\"AI development in France\"`\n",
    "\n",
    "‚úÖ The LLM **combined** both real-time news updates **and** Wikipedia context in a single response plan!\n",
    "\n",
    "Now let's use this to generate a news round-up for France this month on AI. We have to provide this information to the LLM in the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In May 2025, notable developments in AI in France include a significant business agreement by Cykel AI PLC. The company signed a commercial deal with Transpharmation Ltd to deploy Lucy, Cykel's AI recruitment agent. This move is expected to enhance AI applications in business settings (source: Zonebourse, [link](https://www.zonebourse.com/cours/action/CYKEL-AI-DEVELOPMENT-LIMI-62874329/actualite/Cykel-AI-PLC-decroche-un-accord-commercial-de-niveau-entreprise-avec-Transpharmation-Ltd-50099310/)).\n",
      "\n",
      "Additionally, Cykel AI is planning to raise ¬£750,000 through a share placement to fund ongoing operations and implement a new cash reserve strategy (source: Zonebourse, [link](https://www.zonebourse.com/cours/action/CYKEL-AI-DEVELOPMENT-LIMI-62874329/actualite/Cykel-AI-prevoit-de-lever-des-fonds-par-le-biais-d-un-placement-d-actions-50071230/)).\n",
      "\n",
      "For context, AI development in France has been advancing steadily, with a focus on privacy and security. A key player in the field is the French startup Poolside AI, known for developing AI models that automate coding processes. Founded in the U.S., the company moved its headquarters to Paris in August 2024. It has secured significant funding and partnerships, emphasizing the country's growing influence in AI technology.\n"
     ]
    }
   ],
   "source": [
    "if response_message.tool_calls:\n",
    "    messages.append(response_message)\n",
    "    \n",
    "    for tool_call in response_message.tool_calls:\n",
    "        function_name = tool_call.function.name\n",
    "        function_args = json.loads(tool_call.function.arguments)\n",
    "                \n",
    "        # Execute the appropriate function\n",
    "        if function_name == \"get_news\":\n",
    "            function_result = get_news(\n",
    "                query=function_args[\"query\"],\n",
    "                country=function_args[\"country\"], \n",
    "                time_period=function_args[\"time_period\"]\n",
    "            )\n",
    "        elif function_name == \"get_context\":\n",
    "            function_result = get_context(\n",
    "                query=function_args[\"query\"]\n",
    "            )\n",
    "        else:\n",
    "            function_result = f\"Unknown function: {function_name}\"\n",
    "        \n",
    "        messages.append({\n",
    "            \"tool_call_id\": tool_call.id,\n",
    "            \"role\": \"tool\",\n",
    "            \"name\": function_name,\n",
    "            \"content\": json.dumps(function_result, default=str)\n",
    "        })\n",
    "\n",
    "final_response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "print(final_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚öôÔ∏è **How LLM Uses Tool Results for the Final Response**\n",
    "\n",
    "Here‚Äôs a breakdown of what happens in the `handle_tool_calls_and_get_final_answer` function:\n",
    "\n",
    "‚úÖ **Step 1: User Message ‚Üí LLM Decides on Tool Calls**  \n",
    "The user‚Äôs question is first sent to the **LLM** (`model=\"gpt-4o\"`).  \n",
    "Because of the `tool_choice=\"auto\"`, the LLM decides if it needs to call any external tools (like `get_news` or `get_context`) to provide a better answer.\n",
    "\n",
    "‚úÖ **Step 2: LLM‚Äôs Tool Calls ‚Üí Execute Functions**  \n",
    "If tools are called, the system **extracts the tool calls** (`response_message.tool_calls`).  \n",
    "For each tool:\n",
    "- It **reads the function name** and **arguments**.\n",
    "- It **runs the real Python function** (`get_news` or `get_context`) with the arguments from the LLM.\n",
    "- It **saves the results** as tool outputs in the conversation.\n",
    "\n",
    "‚úÖ **Step 3: Feed Tool Results Back to the LLM**  \n",
    "The conversation (`messages`) now includes:\n",
    "- The user‚Äôs original question.\n",
    "- The LLM‚Äôs tool calls.\n",
    "- The **actual tool results** (like real search or context data).\n",
    "\n",
    "We send this **full conversation** back to the LLM in a new chat completion call.  \n",
    "Here, the LLM **uses** the tool results as **real information** to:\n",
    "- **Generate a final, factual answer**.\n",
    "- **Cite real sources** and **summarize** the retrieved data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß LLM is calling tools...\n",
      "   üìû Calling get_news with args: {'query': 'AI development France', 'country': 'FR', 'time_period': 'm'}\n",
      "   üìû Calling get_context with args: {'query': 'AI development in France'}\n",
      "ü§ñ Getting final answer from LLM...\n",
      "\n",
      "============================================================\n",
      "üéØ FINAL ANSWER:\n",
      "============================================================\n",
      "This month in France, there are significant developments in AI. A notable project involves the creation of the largest AI campus in Europe. This initiative is a joint venture involving several major players: MGX, BPI France, Mistral AI, and Nvidia. The project was announced during the \"Choose France\" summit. The campus is set to be located in the √éle-de-France region and aims to significantly boost AI capabilities and infrastructure in Europe.\n",
      "\n",
      "Here are some sources for the detailed news coverage:\n",
      "\n",
      "1. \"[MGX, Nvidia, BPI France and Mistral AI will create the largest AI campus in Europe in France](https://www.channelnews.fr/mgx-bpi-france-mistral-ai-et-nvidia-creent-une-coentreprise-pour-construire-le-plus-grand-campus-ia-deurope-147794)\" - ChannelNews\n",
      "2. \"[Choose France: A new AI campus in √éle-de-France with BPI, MGX, Mistral, and Nvidia](https://www.lemondeinformatique.fr/actualites/lire-choose-france-un-campus-ia-en-ile-de-france-avec-bpi-mgx-mistral-et-nvidia-96873)\" - Le Monde Informatique\n",
      "3. \"[MGX, Bpifrance, Nvidia, and Mistral AI to create the largest AI campus in Europe](https://www.usine-digitale.fr/article/mgx-bpifrance-nvidia-et-mistral-ai-vont-creer-en-france-le-plus-grand-campus-ia-d-europe.N2232196)\" - L'Usine Digitale\n",
      "\n",
      "Additionally, in the broader context of AI, the French startup Poolside AI has made significant strides in the development of AI models that improve and automate coding processes. Founded by former GitHub CTO Jason Warner, the company has become a leading player after securing several rounds of funding and forming strategic partnerships, including with Amazon.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def handle_tool_calls_and_get_final_answer(user_message, tools, client):\n",
    "    \"\"\"\n",
    "    Complete tool calling workflow that returns the final answer\n",
    "    \"\"\"\n",
    "    messages = [{\"role\": \"user\", \"content\": user_message}]\n",
    "    \n",
    "    # Step 1: Initial request - LLM decides which tools to call\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=messages,\n",
    "        tools=tools,\n",
    "        tool_choice=\"auto\"\n",
    "    )\n",
    "    \n",
    "    response_message = response.choices[0].message\n",
    "    messages.append(response_message)\n",
    "    \n",
    "    # Step 2: Check if tools were called\n",
    "    if response_message.tool_calls:\n",
    "        print(\"üîß LLM is calling tools...\")\n",
    "        \n",
    "        # Execute each tool call\n",
    "        for tool_call in response_message.tool_calls:\n",
    "            function_name = tool_call.function.name\n",
    "            function_args = json.loads(tool_call.function.arguments)\n",
    "            \n",
    "            print(f\"   üìû Calling {function_name} with args: {function_args}\")\n",
    "            \n",
    "            # Execute the appropriate function\n",
    "            if function_name == \"get_news\":\n",
    "                function_result = get_news(\n",
    "                    query=function_args[\"query\"],\n",
    "                    country=function_args[\"country\"], \n",
    "                    time_period=function_args[\"time_period\"]\n",
    "                )\n",
    "            elif function_name == \"get_context\":\n",
    "                function_result = get_context(\n",
    "                    query=function_args[\"query\"]\n",
    "                )\n",
    "            else:\n",
    "                function_result = f\"Unknown function: {function_name}\"\n",
    "            \n",
    "            # Add tool result to conversation\n",
    "            messages.append({\n",
    "                \"tool_call_id\": tool_call.id,\n",
    "                \"role\": \"tool\",\n",
    "                \"name\": function_name,\n",
    "                \"content\": json.dumps(function_result)\n",
    "            })\n",
    "        \n",
    "        # Step 3: Get final answer from LLM using tool results\n",
    "        print(\"ü§ñ Getting final answer from LLM...\")\n",
    "        final_response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=messages\n",
    "        )\n",
    "        \n",
    "        return final_response.choices[0].message.content\n",
    "    \n",
    "    else:\n",
    "        # No tools called, return direct response\n",
    "        return response_message.content\n",
    "\n",
    "# Usage example\n",
    "user_query = (\n",
    "    \"Can you tell me what's happening about AI development in France this month? \"\n",
    "    \"And provide some context if needed. Please provide the source of the information with the url.\"\n",
    ")\n",
    "\n",
    "final_answer = handle_tool_calls_and_get_final_answer(user_query, tools, client)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéØ FINAL ANSWER:\")\n",
    "print(\"=\"*60)\n",
    "print(final_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìù **Commentary on Results**\n",
    "\n",
    "‚úÖ **Quality & Relevance**\n",
    "\n",
    "* The final answer is **well-structured** and **directly addresses the user‚Äôs question**.\n",
    "* The **main headline** is clear and supported with **multiple sources**, which adds **credibility**.\n",
    "* The assistant also included **background context** (e.g., Poolside AI‚Äôs activities), demonstrating it used the **Wikipedia summary tool** to enrich the answer.\n",
    "\n",
    "‚úÖ **Use of Sources**\n",
    "\n",
    "* It **cited real URLs**, which came from the `ddg_news_search` function.\n",
    "* **3 sources** were clearly listed, and their names (like ChannelNews, Le Monde Informatique, L‚ÄôUsine Digitale) match actual French tech publications, which boosts trust. Even if two of them are talking exactly about the same thing.\n",
    "\n",
    "‚úÖ **Combining Tools**\n",
    "\n",
    "* The LLM **automatically chose to combine**:\n",
    "\n",
    "  * **Recent news** via `ddg_news_search`\n",
    "  * **Broader context** from Wikipedia\n",
    "* This showcases how **function calling** in the API **lets the LLM decide** what‚Äôs relevant to provide a complete answer.\n",
    "\n",
    "‚úÖ **No Hallucinations**\n",
    "\n",
    "* Because we **supplied real search results** to the LLM, the final output **matches the real world**‚Äînot just hallucinated text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß LLM is calling tools...\n",
      "   üìû Calling get_news with args: {'query': 'AI development', 'country': 'FR', 'time_period': 'm'}\n",
      "   üìû Calling get_news with args: {'query': 'AI development', 'country': 'ES', 'time_period': 'm'}\n",
      "ü§ñ Getting final answer from LLM...\n",
      "\n",
      "============================================================\n",
      "üéØ FINAL ANSWER:\n",
      "============================================================\n",
      "Here's a comparison of AI developments in France and Spain this month, based on recent news articles:\n",
      "\n",
      "**France**\n",
      "\n",
      "1. **Cykel AI Developments**: Cykel AI PLC has made significant strides by signing an enterprise-level commercial agreement with Transpharmation Ltd. and is planning to raise funds to support its operations and cash reserve strategy. The integration of AI agents like Lucy is becoming crucial for business operations across various sectors [Zonebourse](https://www.zonebourse.com/cours/action/CYKEL-AI-DEVELOPMENT-LIMI-62874329/actualite/Cykel-AI-PLC-decroche-un-accord-commercial-de-niveau-entreprise-avec-Transpharmation-Ltd-50099310/).\n",
      "\n",
      "2. **Ethical and Sustainable AI Strategy**: The European Council has called for an ethical, sustainable, inclusive, and human-centric strategy for the adoption of AI in science, emphasizing a European-level plan [Consilium](https://www.consilium.europa.eu/fr/press/press-releases/2025/05/23/council-calls-for-an-inclusive-ethical-sustainable-and-human-centric-strategy-for-the-uptake-of-ai-in-science/).\n",
      "\n",
      "**Spain**\n",
      "\n",
      "1. **AI in Global Enterprises**: Companies like Meta are reaching significant milestones with AI, achieving a billion monthly users, suggesting a solid embrace and integration of AI technologies for business scalability [EL IMPARCIAL](https://www.msn.com/es-mx/dinero/noticias/meta-ai-alcanza-los-mil-millones-de-usuarios-mensuales/ar-AA1FFQ3e).\n",
      "\n",
      "2. **Retail Transformation through AI**: The eRetail Congress 2025 in Spain highlighted transformation strategies in retail, focusing on omnichannel environments and AI-driven experiences, marking a strategic shift to enhance customer engagement and integrate technologies in retail [Europa Press](https://www.europapress.es/comunicados/empresas-00908/noticia-comunicado-eretail-congress-2025-estrategias-transformacion-entornos-omnicanales-experiencias-memorables-20250530134351.html).\n",
      "\n",
      "**Comparison**\n",
      "\n",
      "France is focusing on embedding AI ethically in science, aligning with EU strategies, while also advancing AI through funding and enterprise agreements like those seen with Cykel AI. In contrast, Spain is leveraging AI in consumer-facing industries such as retail and global tech enterprises like Meta, reflecting a market-driven integration of AI solutions to enhance user experiences and achieve scalability. Both countries are actively pursuing AI development, albeit with a focus on different sectors and strategies.\n"
     ]
    }
   ],
   "source": [
    "# Usage example\n",
    "user_query = (\n",
    "    \"Can you tell me what's happening about AI development in France and in Spain this month? \"\n",
    "    \"Make a comparison between the two countries.\"\n",
    "    \"Do not repeat sources.\"\n",
    "    \"And provide some context if needed. Please provide the source of the information with the url.\"\n",
    ")\n",
    "\n",
    "final_answer = handle_tool_calls_and_get_final_answer(user_query, tools, client)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéØ FINAL ANSWER:\")\n",
    "print(\"=\"*60)\n",
    "print(final_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìù **Commentary on the Answer**\n",
    "\n",
    "‚úÖ **Comparison Delivered**\n",
    "\n",
    "* The assistant **understood the comparative aspect** and **structured the answer by country**, highlighting **unique approaches**.\n",
    "\n",
    "‚úÖ **Contextual Layer**\n",
    "\n",
    "* Here the LLM did not use the Wikipedia context tool, this occurs when you let the LLM decide which tool to use.\n",
    "\n",
    "‚úÖ **Real-Time & Verified**\n",
    "\n",
    "* Like before, the assistant **grounded the output** in **real search results**, not hallucinations.\n",
    "\n",
    "üîç **Key Takeaway**\n",
    "This output **showcases the power of tool-based LLM calls**:\n",
    "\n",
    "* **LLM alone** would have no idea what‚Äôs truly happening now in France or Spain.\n",
    "* **LLM + Tools** = **credible**, **structured**, and **tailored** answers based on real sources ‚Äî a huge step beyond hallucination!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bse-nlp-DetGwK6_-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
