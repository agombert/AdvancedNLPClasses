{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "66hrP5h7ttNn"
   },
   "source": [
    "![bse_logo_textminingcourse](https://bse.eu/sites/default/files/bse_logo_small.png)\n",
    "\n",
    "# Advanced Methods in Natural Language Processing - Session 4\n",
    "\n",
    "# Text Classification with AG News Corpus\n",
    "\n",
    "This notebook will guide you through different approaches to text classification using the AG News corpus. We will start with a simple baseline model and gradually move towards more complex and sophisticated models.\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. **[Part 1: Baseline Pipeline with TF-IDF and Linear Model](#part1)**\n",
    "   - 1.1. Loading and Exploring Data\n",
    "   - 1.2. Feature Extraction with TF-IDF\n",
    "   - 1.3. Training a Linear Model\n",
    "   - 1.4. Model Evaluation\n",
    "\n",
    "2. **[Part 2: LSTM Pipeline with One-Hot Encoding](#part2)**\n",
    "   - 2.1. Preprocessing for LSTM\n",
    "   - 2.2. Building a Bidirectional LSTM Model\n",
    "   - 2.3. Training the LSTM Model\n",
    "   - 2.4. Model Evaluation\n",
    "\n",
    "3. **[Part 3: Word Embedding Add-Ons with Word2Vec](#part3)**\n",
    "   - 3.1. Loading Pre-trained Word2Vec Embeddings\n",
    "   - 3.2. Integrating Word2Vec into LSTM Model\n",
    "   - 3.3. Training and Evaluating the Model\n",
    "\n",
    "4. **[Part 4: Model Explainability (LIME / SHAP)](#part4)**\n",
    "   - 4.1. Why Explainability Matters  \n",
    "   - 4.2. Applying LIME to the TF-IDF Model  \n",
    "   - 4.3. Comparing Explanation for LSTM with Word2Vec model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ab7s_m2RvmAh"
   },
   "source": [
    "## Part 0: Metrics Functions to Consider\n",
    "\n",
    "Before diving into the model building and training, it's crucial to establish the metrics we'll use to evaluate our models. In this part, we will define and discuss the different metrics functions that are commonly used in NLP tasks, particularly for text classification:\n",
    "\n",
    "1. **Accuracy**: Measures the proportion of correct predictions among the total number of cases examined. It's a straightforward metric but can be misleading if the classes are imbalanced.\n",
    "\n",
    "2. **Precision and Recall**: Precision measures the proportion of positive identifications that were actually correct, while recall measures the proportion of actual positives that were identified correctly. These metrics are especially important when dealing with imbalanced datasets.\n",
    "\n",
    "3. **F1 Score**: The harmonic mean of precision and recall. It's a good way to show that a classifer has a good balance between precision and recall.\n",
    "\n",
    "4. **Confusion Matrix**: A table used to describe the performance of a classification model on a set of test data for which the true values are known. It allows the visualization of the performance of an algorithm.\n",
    "\n",
    "5. **ROC and AUC**: The receiver operating characteristic curve is a graphical plot that illustrates the diagnostic ability of a binary classifier system. The area under the curve (AUC) represents measure of separability.\n",
    "\n",
    "We will implement these metrics functions using libraries such as scikit-learn, and they will be used to assess and compare the performance of our different models throughout this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "vFvU7C3OwKA6"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# ‚úÖ CLASS TEMPLATE: Metric Comparison Across Models\n",
    "\n",
    "# Create a reusable Metrics class to:\n",
    "# - Store evaluation results (accuracy, precision, recall, F1)\n",
    "# - Compare multiple models side-by-side\n",
    "# - Plot the results using bar charts\n",
    "\n",
    "# üîß Instructions:\n",
    "# 1. Define a class `Metrics` that holds a dictionary to store metrics for each method.\n",
    "# 2. Implement a `.run(y_true, y_pred, method_name)` method that:\n",
    "#    - Computes accuracy, precision, recall, and F1-score.\n",
    "#    - Stores them in the dictionary under the given method name.\n",
    "# 3. Implement a `.plot()` method that:\n",
    "#    - Creates a 2x2 grid of bar plots (one per metric).\n",
    "#    - Displays the comparison of all methods added via `.run()`.\n",
    "\n",
    "# üîç Hint:\n",
    "# - Use `sklearn.metrics` functions like `accuracy_score`, `precision_score`, etc.\n",
    "# - Multiply values by 100 to show percentages.\n",
    "# - Use `plt.subplots()` for subplot creation.\n",
    "# - Add value annotations above each bar using `ax.text()`.\n",
    "\n",
    "# üí° Once implemented, you can use it like this:\n",
    "# metrics = Metrics()\n",
    "# metrics.run(y_true, y_pred_baseline, \"Baseline\")\n",
    "# metrics.run(y_true, y_pred_lstm, \"LSTM\")\n",
    "# metrics.plot()\n",
    "\n",
    "\n",
    "class Metrics:\n",
    "    def __init__(self):\n",
    "        \n",
    "\n",
    "    def run(self, y_true, y_pred, method_name, average='macro'):\n",
    "        \n",
    "\n",
    "    def plot(self):\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w7FZ8v7quizs"
   },
   "source": [
    "## Part 1: Baseline Pipeline with TF-IDF and Linear Model\n",
    "\n",
    "In this part, we will create a baseline model for text classification. This involves:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sPqforMD2v6U"
   },
   "source": [
    "###¬†1. **Loading and Exploring Data**:\n",
    "\n",
    "We will load the AG News corpus and perform necessary preprocessing steps like exploring the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459,
     "referenced_widgets": [
      "a22b7df70c344a0ebf09ee0007b87073",
      "8bd2302b39ac4570ad55e16ca0d6f671",
      "bd11478bf72a4f019f43cfa8dbc1e783",
      "1bdc08e69e4042f18ba93227baa32ac1",
      "2a525e1ad5c44034a68af8927908eb4a",
      "2b7edca124334cf4972038dcf1c02d52",
      "7469455593294f079cd3ebe84ee307f5",
      "923edb3530a54421a5b9d495f7365376",
      "7a94329efae34f1cb787c6b9fa216fd7",
      "e6af5ccf347244c9b50208a3b63a70dd",
      "9c7f258dde654c19899836832eebeb1b",
      "12d2e29130bb437789a541635ec79c94",
      "2b4729cde3c64ff2adc42f5a755a909c",
      "aea6809cb472452289ba2ad2d23d81dd",
      "146775826d8b4cfdb266cb6508895338",
      "af78846a6c5d474596a4ca183fa91a37",
      "430570f44f6d4b908721e9cdec55db65",
      "f834ec3ced2b4e3ea429003d436dc691",
      "a6c1b9106d27445facffcd7fae940b5c",
      "23b671b0254d48f0af8403f2bc157e89",
      "61e16de06a3b4085b91bc9b26d2cf8d1",
      "8c67c5dfe148433595ac047873e61b7c",
      "56cf96a858814490b6a0e71bc8950221",
      "b49c9b2cf95a4f36b04b51dab225b7d4",
      "1d261de3cff34b7fbb079c9afc5809d2",
      "786cf4c1e6604d289277334cfa710350",
      "faf57723768b48b99a2ff547099e5a52",
      "b07e6e23f24c49c68f724d3dbbb65df6",
      "ceb1b84013b54e4ea46e6eb99c6a6e52",
      "4298532691da464f8fcf85f6aff78ae3",
      "438a293d56344bbda0c123e95eedfbd5",
      "cca526a8d17c4d64946af5fa8468ed11",
      "ea6bc7e91240460e9e366921fc4a68f8",
      "8f23a9383aa940debdf5045f06480cbe",
      "996e38a0cdce474cad7154102c6241c4",
      "c439b1ea83fd4d16a9974a243fb76aa3",
      "5cd2c79a4602466785f8cd5a5fc35e23",
      "12ac756a0257424cbe3f24fbf5acf9eb",
      "a159206133e94744ac85c73a03c21797",
      "74da8262aff642d686a404a95ef9a2f1",
      "43988dc7dcd745a89e73aa0ad0ea3833",
      "415f34bad60c465eb8055b56b361158c",
      "f7687706375441b49b5286f60183efa1",
      "1a9467e3b6a24c63b4f52f336e6fca38"
     ]
    },
    "id": "KrJTmiYZzaR9",
    "outputId": "57b20501-c42a-4f3f-a9a8-82813efdcb9b"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the 'ag_news' dataset\n",
    "dataset = load_dataset(\"ag_news\")\n",
    "\n",
    "# Explore the structure of the dataset\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CzVwWxcjzgNy"
   },
   "source": [
    "Let's create stratified samples for training and validation sets ensuring that each class is represented in proportion to its frequency. It will go faster with just a sample, and we will be able to make tests on validation test before trying to work on the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "qrRvFzrGzdAx"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = dataset['train']['text']\n",
    "labels = dataset['train']['label']\n",
    "\n",
    "test_data = dataset['test']['text']\n",
    "test_labels = dataset['test']['label']\n",
    "\n",
    "# Stratified split to create a smaller training and validation set\n",
    "train_data, valid_data, train_labels, valid_labels = train_test_split(\n",
    "    data, labels, stratify=labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Further split to get 10k and 2k samples respectively\n",
    "train_data, _, train_labels, _ = train_test_split(\n",
    "    train_data, train_labels, stratify=train_labels, train_size=10000, random_state=42\n",
    ")\n",
    "valid_data, _, valid_labels, _ = train_test_split(\n",
    "    valid_data, valid_labels, stratify=valid_labels, train_size=2000, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 619
    },
    "id": "HXWQzYN91YDA",
    "outputId": "657b5ada-0523-40f0-bb7f-9eb1bb8d5d11"
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# ‚úÖ TASK: Visualize Word Distributions Per Class with Word Clouds\n",
    "\n",
    "# Goal:\n",
    "# - Create word clouds for each class label to visually inspect frequent terms.\n",
    "# - This helps you understand which words dominate each topic (e.g., sports, business, etc.)\n",
    "\n",
    "# üß∞ Required Libraries:\n",
    "# - `wordcloud.WordCloud` for generating word clouds\n",
    "# - `nltk.corpus.stopwords` for filtering out common English words\n",
    "# - `matplotlib.pyplot` for plotting\n",
    "# - `collections.defaultdict` for grouping text by label\n",
    "\n",
    "# ü™ú Instructions:\n",
    "\n",
    "# 1. Import the required libraries.\n",
    "# 2. Download and prepare the list of English stopwords using NLTK.\n",
    "# 3. Create a dictionary `label_data` (e.g., with `defaultdict`) to accumulate all text per class label.\n",
    "# 4. Set up a 2x2 subplot layout using `plt.subplots` to visualize 4 categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 435
    },
    "id": "bTITVZia2aTG",
    "outputId": "cd3d704a-50aa-4ff7-b4bd-c4157edf1d24"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ‚úÖ TASK: Visualize Class Distribution with a Pie Chart\n",
    "\n",
    "# Goal:\n",
    "# - Create a pie chart to show the proportion of each class in the training dataset.\n",
    "# - This helps you detect class imbalance, which is important for model training and evaluation.\n",
    "\n",
    "# üß∞ Required Libraries:\n",
    "# - `collections.Counter` to count how many examples exist per label.\n",
    "# - `matplotlib.pyplot` to create the pie chart.\n",
    "\n",
    "# ü™ú Instructions:\n",
    "\n",
    "# 1. Use `Counter` to count how many times each label appears in `train_labels`.\n",
    "# 2. Convert label indices to label names (e.g., 'World', 'Business') using the `labels` dictionary.\n",
    "# 3. Prepare data for plotting\n",
    "# 4. Use `plt.pie()` to draw the pie chart.\n",
    "# 5. Call `plt.axis('equal')` to make sure the pie chart is circular.\n",
    "# 6. Add a title and display the chart with `plt.show()`.\n",
    "\n",
    "# üéØ Output: A pie chart showing the proportion of news categories in your dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HJl2q_rlvZGK"
   },
   "source": [
    "### 2. **Feature Extraction with TF-IDF**:\n",
    "\n",
    "We will convert the text data into numerical form using the TF-IDF vectorization technique. We will use the `Pipeline` class from scikit-learn which is really practical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "CdthwJiTueEE"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ‚úÖ TASK: Build a Baseline Text Classification Pipeline\n",
    "\n",
    "# Goal:\n",
    "# - Create a text classification pipeline that transforms text data into TF-IDF features\n",
    "#   and trains a Logistic Regression model on them.\n",
    "\n",
    "# üß∞ Required Tools:\n",
    "# - `TfidfVectorizer` to convert raw text into numerical features.\n",
    "# - `LogisticRegression` as a simple yet effective classifier for baseline comparison.\n",
    "# - `Pipeline` to combine preprocessing and model training into a single object.\n",
    "\n",
    "# ü™ú Instructions:\n",
    "\n",
    "# 1. Create a `Pipeline` \n",
    "# 2. Fit the pipeline on your training data\n",
    "# 3. Make predictions on the validation set using `.predict(valid_data)`.\n",
    "\n",
    "# üéØ Output:\n",
    "# - A trained model that you can use to make predictions and evaluate performance.\n",
    "# - Predicted labels for the validation set stored in `valid_preds`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "BFknIrrF4TW9"
   },
   "outputs": [],
   "source": [
    "metrics_val= Metrics()\n",
    "metrics_val.run(valid_labels, valid_preds, \"basic TF-IDF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TEaSlme-vagC"
   },
   "source": [
    "### 3. **Training with Cross Validation**:\n",
    "\n",
    "We will train a linear classifier (such as Logistic Regression) using the extracted features, `Pipeline` module and cross validation with `GridSearchCV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d2R52Bt5vcmB",
    "outputId": "a7a4aa67-0329-46c2-bf49-3e131fe4aea4"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# ‚úÖ TASK: Tune Your TF-IDF + Logistic Regression Pipeline using Grid Search\n",
    "\n",
    "# Goal:\n",
    "# - Use `GridSearchCV` to find the best combination of hyperparameters for the pipeline.\n",
    "# - Improve performance by systematically testing different settings for `TfidfVectorizer`.\n",
    "\n",
    "# üß∞ Required Tools:\n",
    "# - `GridSearchCV`: for systematic search over hyperparameter space with cross-validation.\n",
    "# - `param_grid`: dictionary defining which parameters to tune and their candidate values.\n",
    "\n",
    "# ü™ú Instructions:\n",
    "\n",
    "# 1. Define the parameter grid\n",
    "# 2. Create a `GridSearchCV` object\n",
    "# 3. Fit the grid search on the training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IwwFma1dvcsd"
   },
   "source": [
    "### 4. **Model Evaluation**:\n",
    "\n",
    "We will evaluate the performance of our model on a separate test set using various metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 899
    },
    "id": "nAxJ_28MvanR",
    "outputId": "25261fcb-dc1a-496d-86ef-e8d52fbb4753"
   },
   "outputs": [],
   "source": [
    "metrics_val.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c4eZdme7vokh"
   },
   "source": [
    "## Part 2: LSTM Pipeline with One-Hot Encoding\n",
    "\n",
    "In this part, we'll explore a more complex model using LSTM:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yndnfwXa8qQC"
   },
   "source": [
    "### 1. **Preprocessing for LSTM**:\n",
    "\n",
    "We'll prepare the text data for LSTM, which involves tokenization and converting words to one-hot encoded vectors.\n",
    "\n",
    "### üî† Tokenization & Vocabulary\n",
    "\n",
    "We use Keras's `Tokenizer` to convert raw text into sequences of integers.\n",
    "- `num_words=5000` limits the vocabulary to the most frequent 5000 words.\n",
    "- The tokenizer is **fit only on the training data** to avoid data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# Define vocabulary size (maximum number of words to keep)\n",
    "vocab_size = 5000  # üîß Hyperparameter: Can be increased or decreased based on your dataset size\n",
    "\n",
    "# Initialize the tokenizer\n",
    "\n",
    "\n",
    "# Fit the tokenizer on the training text data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üßÆ Text to Sequence\n",
    "\n",
    "Now that the tokenizer has learned the vocabulary:\n",
    "- It transforms each sentence into a list of word indices.\n",
    "- Words not in the top `vocab_size` are ignored.\n",
    "\n",
    "Example: `\"the cat sat\"` ‚Üí `[1, 45, 213]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert training and validation texts to sequences\n",
    "sequences_train = \n",
    "sequences_valid = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìê Padding Sequences\n",
    "\n",
    "Neural networks require **fixed-length input**, so we:\n",
    "- **Pad shorter sequences** with zeros.\n",
    "- **Truncate longer ones** to the `max_length`.\n",
    "\n",
    "`padding='post'` adds padding **after** the sequence (e.g., `[45, 213, 0, 0, 0]`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Set maximum input length\n",
    "max_length = 128\n",
    "\n",
    "# Pad or truncate the sequences to fixed length\n",
    "padded_sequences_train = \n",
    "padded_sequences_valid = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéØ One-Hot Encode Labels\n",
    "\n",
    "For multi-class classification with neural networks, we need to:\n",
    "- Convert integer class labels to one-hot encoded vectors.\n",
    "  - Class `2` in 4-class problem ‚Üí `[0, 0, 1, 0]`\n",
    "- This format is required by the softmax output layer in our model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Determine number of unique output classes\n",
    "num_classes = len(set(train_labels))\n",
    "\n",
    "# One-hot encode the labels\n",
    "train_labels_lstm = \n",
    "valid_labels_lstm = \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6v-l49eA8qp-"
   },
   "source": [
    "### 2. **Building a Bidirectional LSTM Model**:\n",
    "\n",
    "We'll design a neural network with a Bidirectional LSTM layer to capture context from both directions in the text.\n",
    "\n",
    "### üß± Building the Neural Network\n",
    "\n",
    "We use Keras's `Sequential` model for simplicity. We'll define our LSTM-based architecture step-by-step next.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Bidirectional, Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üß© Model Layers\n",
    "\n",
    "- `Embedding`: Transforms integer word indices into dense vectors.\n",
    "- `Bidirectional LSTM`: Processes the sequence both **forward and backward** for richer context.\n",
    "- `Dense`: Final layer with softmax activation for **multi-class classification**.\n",
    "\n",
    "Each sentence becomes a sequence of vectors, processed to output a probability over each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Embedding\n",
    "    Bidirectional\n",
    "    Dense\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚öôÔ∏è Model Compilation\n",
    "\n",
    "We compile the model with:\n",
    "- `adam` optimizer (adaptive learning rate)\n",
    "- `categorical_crossentropy` for multi-class output\n",
    "- Additional metrics: `accuracy`, `precision`, and `recall` for deeper evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\n",
    "    loss=\n",
    "    metrics=\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üßæ Model Summary\n",
    "\n",
    "Let‚Äôs take a quick look at the number of parameters, layer types, and output shapes in our model.\n",
    "\n",
    "‚úÖ This helps validate that the model is structured as intended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "27WvWMEo8q2-",
    "outputId": "1f14bab3-6305-414c-d5a6-df624133c8c2"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RvxIuYkb8rDo"
   },
   "source": [
    "### 3. **Training the LSTM Model**:\n",
    "\n",
    "We'll train our LSTM model on the preprocessed text data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2BTowIVP8rRL",
    "outputId": "f0c25cdf-2da9-4139-881c-a37e35376992"
   },
   "outputs": [],
   "source": [
    "history = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_jo6_aZh81lt"
   },
   "source": [
    "### 4. **Model Evaluation**:\n",
    "\n",
    "*Similar* to Part 1, we will evaluate our model's performance using appropriate metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "30qA_9FCtntO",
    "outputId": "77462ad4-5a62-4c36-b37c-d68699277f51"
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(padded_sequences_valid)\n",
    "valid_preds = np.argmax(predictions, axis=1)\n",
    "metrics_val.run(valid_labels, valid_preds, \"BiLSTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 899
    },
    "id": "GauRhtEfE5Vw",
    "outputId": "91ae719d-5a4c-4307-aae7-43708a041e28"
   },
   "outputs": [],
   "source": [
    "metrics_val.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pECtNMJ5vpoh"
   },
   "source": [
    "## Part 3: Word Embedding Add-Ons with Word2Vec\n",
    "\n",
    "This part focuses on integrating pre-trained word embeddings into our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CStwSkObFFne"
   },
   "source": [
    "## 1. **Loading Pre-trained Word2Vec Embeddings**:\n",
    "\n",
    "We'll load Word2Vec embeddings pre-trained on a large corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dGMnHbICFCMA",
    "outputId": "b53cdbd5-b228-4815-fcca-b9b574fc05c8"
   },
   "outputs": [],
   "source": [
    "from staticvectors import StaticVectors\n",
    "\n",
    "word2vec_model = StaticVectors(\"neuml/word2vec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FJZNdvmpFCeS"
   },
   "source": [
    "## 2. **Integrating Word2Vec into LSTM Model**:\n",
    "We'll use these embeddings as inputs to our LSTM model, potentially enhancing its ability to understand context and semantics.\n",
    "\n",
    "### üì¶ Preparing the Word2Vec Embedding Matrix\n",
    "\n",
    "We will now create an **embedding matrix** that maps each word in our tokenizer vocabulary to its **pre-trained Word2Vec vector**.\n",
    "\n",
    "- We initialize a matrix of zeros with shape `(vocab_size, 300)`\n",
    "- 300 is the dimensionality of Google's pre-trained Word2Vec vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üßÆ Embedding Matrix Initialization\n",
    "\n",
    "Every row `i` in this matrix will store the 300-dimensional Word2Vec vector for the `i-th` word in our vocabulary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîç Filling the Embedding Matrix\n",
    "\n",
    "For each word in our tokenizer's vocabulary:\n",
    "- We look up its corresponding vector from the pre-trained Word2Vec model\n",
    "- If it's not found (OOV word), we leave the row as zeros\n",
    "- We use `tqdm` to track progress, which is helpful when processing large vocabularies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word, i in tqdm(tokenizer.word_index.items()):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üß± Model with Word2Vec Embeddings\n",
    "\n",
    "- The `Embedding` layer now uses our **pre-trained Word2Vec weights**\n",
    "- `trainable=False` means we freeze the embeddings (no updates during training)\n",
    "- Same `Bidirectional LSTM` and `Dense` classifier as before\n",
    "\n",
    "### ‚öôÔ∏è Compile the Model\n",
    "\n",
    "We compile with:\n",
    "- `adam` optimizer\n",
    "- `categorical_crossentropy` loss for multi-class classification\n",
    "- Accuracy as our evaluation metric\n",
    "\n",
    "Then we print the model architecture to review.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BjOCkI44FCxc",
    "outputId": "d13266e5-3642-402b-cf66-d4d567dc43c4"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding\n",
    "    Bidirectional\n",
    "    Dense\n",
    "])\n",
    "\n",
    "model.compile\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ev7ioVYxFDC1"
   },
   "source": [
    "## 3. **Training and Evaluating the Model**:\n",
    "We'll train our model with these new embeddings and evaluate to see if there's an improvement in performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "a96kqkopFDUX",
    "outputId": "15c7a2d2-2dd8-4e2f-aa04-93a1da736d48"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Setup early stopping to stop training when validation loss stops improving\n",
    "early_stopping = EarlyStopping(\n",
    "    \n",
    ")\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    padded_sequences_train,\n",
    "    train_labels_lstm,\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    validation_data=(padded_sequences_valid, valid_labels_lstm),\n",
    "    callbacks=[early_stopping]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pHa1yN24GWHU"
   },
   "source": [
    "## 4. **Model Evaluation**:\n",
    "\n",
    "Similar to previous parts, we will evaluate our model's performance using appropriate metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "p2xTLGFwvs8a",
    "outputId": "88b06616-4fbc-42bd-ca1a-f7e8053d45df"
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(padded_sequences_valid)\n",
    "valid_preds = np.argmax(predictions, axis=1)\n",
    "metrics_val.run(valid_labels, valid_preds, \"BiLSTM + W2V\")\n",
    "metrics_val.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0xASMzlbvtgF"
   },
   "source": [
    "## Part 4: Model Explainability (LIME / SHAP)\n",
    "\n",
    "As machine learning models become more powerful, they also become more complex and opaque ‚Äî especially deep learning models like LSTMs or transformer-based architectures. This complexity makes it harder to understand *why* a model makes a specific prediction.\n",
    "\n",
    "In this part, we will explore **model explainability**, a crucial step in building trustworthy and transparent machine learning systems.\n",
    "\n",
    "### 4.1 Why Explainability Matters\n",
    "\n",
    "Imagine you‚Äôve built a model that predicts whether a customer is likely to churn, or whether a loan should be approved. Even if your model is 90% accurate, you might be asked:\n",
    "\n",
    "> ü§î \"But why did the model make that decision?\"\n",
    "\n",
    "This is where **explainability** becomes essential.\n",
    "\n",
    "#### Why it's important:\n",
    "\n",
    "- **Trust**: Users are more likely to trust predictions they can understand.\n",
    "- **Debugging**: Helps identify spurious correlations or biases in the model.\n",
    "- **Fairness & Ethics**: Ensures decisions are not based on sensitive or discriminatory attributes.\n",
    "- **Regulatory Compliance**: In some domains (like finance or healthcare), explainability is required by law.\n",
    "\n",
    "#### Two Main Categories of Explainability:\n",
    "\n",
    "1. **Global Explanations**: Understanding the overall model behavior  \n",
    "   _Example: Which words generally influence sentiment predictions the most?_\n",
    "\n",
    "2. **Local Explanations**: Understanding individual predictions  \n",
    "   _Example: Why was *this* review classified as negative?_\n",
    "\n",
    "We'll focus primarily on **local explanations** using:\n",
    "- `LIME` (for simpler models like TF-IDF + Logistic Regression)\n",
    "\n",
    "Let‚Äôs begin by applying LIME to our TF-IDF baseline model.\n",
    "\n",
    "### 4.2 üß™ Applying LIME to the TF-IDF Model\n",
    "\n",
    "Now that we understand **why explainability matters**, let's start by applying **LIME** (Local Interpretable Model-agnostic Explanations) to our first model:  \n",
    "‚û°Ô∏è A **TF-IDF + Logistic Regression** pipeline.\n",
    "\n",
    "LIME works by slightly perturbing the input text and seeing how the model prediction changes.  \n",
    "From this, it builds a **local, interpretable surrogate model** (like a linear regression) to approximate the complex model's behavior near that input.\n",
    "\n",
    "We'll explain:\n",
    "- A single prediction for a text sample\n",
    "- Which words had the most impact (positive or negative) on the predicted label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime.lime_text import LimeTextExplainer\n",
    "import shap\n",
    "\n",
    "# Fixed version of the TF-IDF LIME explainer function\n",
    "def explain_tfidf_prediction(text_instance, pipeline, class_names):\n",
    "    # Create a LIME text explainer\n",
    "    explainer = LimeTextExplainer(class_names=class_names)\n",
    "    \n",
    "    # Get explanation for the prediction\n",
    "    exp = explainer.explain_instance(\n",
    "        text_instance, \n",
    "        pipeline.predict_proba, \n",
    "        num_features=10,\n",
    "        top_labels=len(class_names)  # Explain all classes\n",
    "    )\n",
    "    \n",
    "    # Display basic information\n",
    "    print(f\"Text: {text_instance}\")\n",
    "    pred_class = pipeline.predict([text_instance])[0]\n",
    "    print(f\"Predicted class: {class_names[pred_class]}\")\n",
    "    \n",
    "    # Get probabilities for all classes\n",
    "    probs = pipeline.predict_proba([text_instance])[0]\n",
    "    print(\"\\nClass probabilities:\")\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        print(f\"{class_name}: {probs[i]:.4f}\")\n",
    "    \n",
    "    # Create visualization for each class\n",
    "    plt.figure(figsize=(20, 15))\n",
    "    \n",
    "    # Get the labels that LIME actually explained\n",
    "    top_labels = exp.available_labels()\n",
    "    \n",
    "    for i, label_id in enumerate(top_labels):\n",
    "        plt.subplot(2, 2, i+1)\n",
    "        \n",
    "        # Get the explanation for this class\n",
    "        exp_list = exp.as_list(label=label_id)\n",
    "        \n",
    "        # Extract words and weights\n",
    "        words = [x[0] for x in exp_list]\n",
    "        weights = [x[1] for x in exp_list]\n",
    "        \n",
    "        # Sort for better visualization\n",
    "        pairs = sorted(zip(words, weights), key=lambda x: x[1])\n",
    "        words = [x[0] for x in pairs]\n",
    "        weights = [x[1] for x in pairs]\n",
    "        \n",
    "        # Create bar chart\n",
    "        colors = ['red' if w < 0 else 'green' for w in weights]\n",
    "        y_pos = np.arange(len(words))\n",
    "        \n",
    "        plt.barh(y_pos, weights, color=colors)\n",
    "        plt.yticks(y_pos, words)\n",
    "        plt.title(f\"Explanation for class: {class_names[label_id]}\")\n",
    "        plt.axvline(x=0, color='black', linestyle='-', alpha=0.5)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print top contributing words for each class\n",
    "    for label_id in top_labels:\n",
    "        print(f\"\\nTop features for class: {class_names[label_id]}\")\n",
    "        exp_list = exp.as_list(label=label_id)\n",
    "        for word, weight in exp_list:\n",
    "            print(f\"{word}: {weight:.4f}\")\n",
    "    \n",
    "    return exp\n",
    "\n",
    "# Example text from test set\n",
    "example_text = test_data[0]\n",
    "class_names = ['World', 'Sports', 'Business', 'Sci/Tech']\n",
    "lime_exp_tfidf = explain_tfidf_prediction(example_text, grid_search.best_estimator_, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üß† Interpretation of LIME Explanation\n",
    "\n",
    "Let's break down what LIME revealed about the model's reasoning for this particular prediction.\n",
    "\n",
    "#### ‚úÖ Predicted Class: **Business**\n",
    "\n",
    "LIME shows us the **top 10 words** that contributed **positively** or **negatively** to each possible class (Business, World, Sci/Tech, Sports).\n",
    "\n",
    "#### üí¨ For Class: **Business**\n",
    "- Words like **\"Federal\"**, **\"firm\"**, and **\"pension\"** have **positive weights**, meaning they support the Business prediction.\n",
    "- The word **\"talks\"** actually detracts from the Business prediction (negative weight), suggesting it's a bit ambiguous.\n",
    "\n",
    "#### üåç For Class: **World**\n",
    "- Interestingly, **\"talks\"** strongly supports the **World** class here.\n",
    "- Other Business-related terms (e.g., **\"Federal\"**, **\"firm\"**) detract from a World prediction.\n",
    "\n",
    "#### üí° Insights:\n",
    "- Words like **\"workers\"**, **\"Unions\"**, and **\"say\"** appear across multiple classes with small influence, showing they‚Äôre more generic.\n",
    "- **\"talks\"** is context-dependent ‚Äì LIME helps us **disentangle how the same word can shift meaning** depending on the rest of the sentence.\n",
    "\n",
    "üß≠ **Takeaway**: LIME helps us peek inside the model's black box and see *which features are driving predictions*. It also shows that certain words may support multiple classes, but with different intensities.\n",
    "\n",
    "---\n",
    "\n",
    "Ready to move on? Let‚Äôs now explore:\n",
    "\n",
    "### 4.3 üìä Comparing Explanations for LSTM and Word2Vec Models\n",
    "\n",
    "‚û°Ô∏è Here, we'll try to interpret more **complex models** (like LSTM and Word2Vec-based models) using LIME and compare how their reasoning differs from the simpler TF-IDF model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_text_for_lstm(text, tokenizer, max_length):\n",
    "    \"\"\"Prepare text input for LSTM model\"\"\"\n",
    "    from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "    sequences = tokenizer.texts_to_sequences([text])\n",
    "    padded_seq = pad_sequences(sequences, maxlen=max_length)\n",
    "    return padded_seq\n",
    "\n",
    "def lstm_predict_proba(texts):\n",
    "    \"\"\"Prediction function for LIME to use with LSTM model\"\"\"\n",
    "    result = np.zeros((len(texts), len(class_names)))\n",
    "    for i, text in enumerate(texts):\n",
    "        padded = prepare_text_for_lstm(text, tokenizer, max_length)\n",
    "        pred = model.predict(padded, verbose=0)\n",
    "        result[i] = pred[0]\n",
    "    return result\n",
    "\n",
    "def explain_lstm_prediction(text_instance, class_names):\n",
    "    # Create a LIME text explainer\n",
    "    explainer = LimeTextExplainer(class_names=class_names)\n",
    "    \n",
    "    # Get explanation for the prediction\n",
    "    exp = explainer.explain_instance(\n",
    "        text_instance, \n",
    "        lstm_predict_proba, \n",
    "        num_features=10,\n",
    "        top_labels=len(class_names)  # Explain all classes\n",
    "    )\n",
    "    \n",
    "    # Display basic information\n",
    "    print(f\"Text: {text_instance}\")\n",
    "    padded = prepare_text_for_lstm(text_instance, tokenizer, max_length)\n",
    "    prediction = model.predict(padded, verbose=0)\n",
    "    predicted_class = np.argmax(prediction[0])\n",
    "    print(f\"Predicted class: {class_names[predicted_class]}\")\n",
    "    \n",
    "    # Get probabilities for all classes\n",
    "    probs = prediction[0]\n",
    "    print(\"\\nClass probabilities:\")\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        print(f\"{class_name}: {probs[i]:.4f}\")\n",
    "    \n",
    "    # Create visualization for each class\n",
    "    plt.figure(figsize=(20, 15))\n",
    "    \n",
    "    # Get the labels that LIME actually explained\n",
    "    top_labels = exp.available_labels()\n",
    "    \n",
    "    for i, label_id in enumerate(top_labels):\n",
    "        plt.subplot(2, 2, i+1)\n",
    "        \n",
    "        # Get the explanation for this class\n",
    "        exp_list = exp.as_list(label=label_id)\n",
    "        \n",
    "        # Extract words and weights\n",
    "        words = [x[0] for x in exp_list]\n",
    "        weights = [x[1] for x in exp_list]\n",
    "        \n",
    "        # Sort for better visualization\n",
    "        pairs = sorted(zip(words, weights), key=lambda x: x[1])\n",
    "        words = [x[0] for x in pairs]\n",
    "        weights = [x[1] for x in pairs]\n",
    "        \n",
    "        # Create bar chart\n",
    "        colors = ['red' if w < 0 else 'green' for w in weights]\n",
    "        y_pos = np.arange(len(words))\n",
    "        \n",
    "        plt.barh(y_pos, weights, color=colors)\n",
    "        plt.yticks(y_pos, words)\n",
    "        plt.title(f\"Explanation for class: {class_names[label_id]}\")\n",
    "        plt.axvline(x=0, color='black', linestyle='-', alpha=0.5)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print top contributing words for each class\n",
    "    for label_id in top_labels:\n",
    "        print(f\"\\nTop features for class: {class_names[label_id]}\")\n",
    "        exp_list = exp.as_list(label=label_id)\n",
    "        for word, weight in exp_list:\n",
    "            print(f\"{word}: {weight:.4f}\")\n",
    "    \n",
    "    return exp\n",
    "\n",
    "example_text = test_data[0]\n",
    "model_exp_lime = explain_lstm_prediction(example_text, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîç LIME Explanation for LSTM Model\n",
    "\n",
    "#### üß† Sentence Analyzed:\n",
    "> \"Fears for T N pension after talks Unions representing workers at Turner Newall say they are 'disappointed' after talks with stricken parent firm Federal Mogul.\"\n",
    "\n",
    "#### ‚úÖ Predicted Class: **Sci/Tech**  \n",
    "With a **very high probability (78.35%)**, the LSTM model predicted this text belongs to **Sci/Tech**.\n",
    "\n",
    "#### üìä Class Probabilities:\n",
    "- Sci/Tech: **0.7835**\n",
    "- World: 0.0995\n",
    "- Business: 0.0839\n",
    "- Sports: 0.0331\n",
    "\n",
    "---\n",
    "\n",
    "### üí° What LIME Reveals\n",
    "\n",
    "#### Top Features Supporting **Sci/Tech**:\n",
    "- Common connectors like **\"they\"**, **\"after\"**, **\"are\"**, **\"with\"**, and **\"at\"** surprisingly contribute **positively** to Sci/Tech.\n",
    "- Words like **\"firm\"** and **\"talks\"**, which might intuitively relate to Business or World, actually **reduce** the Sci/Tech probability here.\n",
    "\n",
    "#### Across Other Classes:\n",
    "- Most of the same function words (**\"they\"**, **\"after\"**, **\"with\"**) appear as **negative** contributors to **World**, **Business**, and **Sports** classes.\n",
    "- Words like **\"firm\"** slightly **boost** the Business class but are downplayed for Sci/Tech.\n",
    "- In the **Sports** class, all top words negatively influence the prediction, confirming it‚Äôs a poor match.\n",
    "\n",
    "---\n",
    "\n",
    "### üß† Interpretation:\n",
    "Unlike the TF-IDF model, which focused on *specific content words*, the LSTM model seems to be relying heavily on **syntactic or structural features** (like function words and word order). This could be due to:\n",
    "- The sequential nature of LSTM, which captures **contextual dependencies**\n",
    "- A possible **lack of domain-specific keywords** driving this prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "FJZNdvmpFCeS"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "bse-nlp-DetGwK6_-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "12ac756a0257424cbe3f24fbf5acf9eb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "12d2e29130bb437789a541635ec79c94": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2b4729cde3c64ff2adc42f5a755a909c",
       "IPY_MODEL_aea6809cb472452289ba2ad2d23d81dd",
       "IPY_MODEL_146775826d8b4cfdb266cb6508895338"
      ],
      "layout": "IPY_MODEL_af78846a6c5d474596a4ca183fa91a37"
     }
    },
    "146775826d8b4cfdb266cb6508895338": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_61e16de06a3b4085b91bc9b26d2cf8d1",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_8c67c5dfe148433595ac047873e61b7c",
      "value": " 1.23M/1.23M [00:00&lt;00:00, 6.33MB/s]"
     }
    },
    "1a9467e3b6a24c63b4f52f336e6fca38": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1bdc08e69e4042f18ba93227baa32ac1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e6af5ccf347244c9b50208a3b63a70dd",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_9c7f258dde654c19899836832eebeb1b",
      "value": " 18.6M/18.6M [00:00&lt;00:00, 23.5MB/s]"
     }
    },
    "1d261de3cff34b7fbb079c9afc5809d2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4298532691da464f8fcf85f6aff78ae3",
      "max": 120000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_438a293d56344bbda0c123e95eedfbd5",
      "value": 120000
     }
    },
    "23b671b0254d48f0af8403f2bc157e89": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2a525e1ad5c44034a68af8927908eb4a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2b4729cde3c64ff2adc42f5a755a909c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_430570f44f6d4b908721e9cdec55db65",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_f834ec3ced2b4e3ea429003d436dc691",
      "value": "Downloading data: 100%"
     }
    },
    "2b7edca124334cf4972038dcf1c02d52": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "415f34bad60c465eb8055b56b361158c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4298532691da464f8fcf85f6aff78ae3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "430570f44f6d4b908721e9cdec55db65": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "438a293d56344bbda0c123e95eedfbd5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "43988dc7dcd745a89e73aa0ad0ea3833": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "56cf96a858814490b6a0e71bc8950221": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b49c9b2cf95a4f36b04b51dab225b7d4",
       "IPY_MODEL_1d261de3cff34b7fbb079c9afc5809d2",
       "IPY_MODEL_786cf4c1e6604d289277334cfa710350"
      ],
      "layout": "IPY_MODEL_faf57723768b48b99a2ff547099e5a52"
     }
    },
    "5cd2c79a4602466785f8cd5a5fc35e23": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f7687706375441b49b5286f60183efa1",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_1a9467e3b6a24c63b4f52f336e6fca38",
      "value": " 7600/7600 [00:00&lt;00:00, 172161.37 examples/s]"
     }
    },
    "61e16de06a3b4085b91bc9b26d2cf8d1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7469455593294f079cd3ebe84ee307f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "74da8262aff642d686a404a95ef9a2f1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "786cf4c1e6604d289277334cfa710350": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cca526a8d17c4d64946af5fa8468ed11",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_ea6bc7e91240460e9e366921fc4a68f8",
      "value": " 120000/120000 [00:00&lt;00:00, 352554.14 examples/s]"
     }
    },
    "7a94329efae34f1cb787c6b9fa216fd7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8bd2302b39ac4570ad55e16ca0d6f671": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2b7edca124334cf4972038dcf1c02d52",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_7469455593294f079cd3ebe84ee307f5",
      "value": "Downloading data: 100%"
     }
    },
    "8c67c5dfe148433595ac047873e61b7c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8f23a9383aa940debdf5045f06480cbe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_996e38a0cdce474cad7154102c6241c4",
       "IPY_MODEL_c439b1ea83fd4d16a9974a243fb76aa3",
       "IPY_MODEL_5cd2c79a4602466785f8cd5a5fc35e23"
      ],
      "layout": "IPY_MODEL_12ac756a0257424cbe3f24fbf5acf9eb"
     }
    },
    "923edb3530a54421a5b9d495f7365376": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "996e38a0cdce474cad7154102c6241c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a159206133e94744ac85c73a03c21797",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_74da8262aff642d686a404a95ef9a2f1",
      "value": "Generating test split: 100%"
     }
    },
    "9c7f258dde654c19899836832eebeb1b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a159206133e94744ac85c73a03c21797": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a22b7df70c344a0ebf09ee0007b87073": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8bd2302b39ac4570ad55e16ca0d6f671",
       "IPY_MODEL_bd11478bf72a4f019f43cfa8dbc1e783",
       "IPY_MODEL_1bdc08e69e4042f18ba93227baa32ac1"
      ],
      "layout": "IPY_MODEL_2a525e1ad5c44034a68af8927908eb4a"
     }
    },
    "a6c1b9106d27445facffcd7fae940b5c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aea6809cb472452289ba2ad2d23d81dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a6c1b9106d27445facffcd7fae940b5c",
      "max": 1234829,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_23b671b0254d48f0af8403f2bc157e89",
      "value": 1234829
     }
    },
    "af78846a6c5d474596a4ca183fa91a37": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b07e6e23f24c49c68f724d3dbbb65df6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b49c9b2cf95a4f36b04b51dab225b7d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b07e6e23f24c49c68f724d3dbbb65df6",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_ceb1b84013b54e4ea46e6eb99c6a6e52",
      "value": "Generating train split: 100%"
     }
    },
    "bd11478bf72a4f019f43cfa8dbc1e783": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_923edb3530a54421a5b9d495f7365376",
      "max": 18585438,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7a94329efae34f1cb787c6b9fa216fd7",
      "value": 18585438
     }
    },
    "c439b1ea83fd4d16a9974a243fb76aa3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_43988dc7dcd745a89e73aa0ad0ea3833",
      "max": 7600,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_415f34bad60c465eb8055b56b361158c",
      "value": 7600
     }
    },
    "cca526a8d17c4d64946af5fa8468ed11": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ceb1b84013b54e4ea46e6eb99c6a6e52": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e6af5ccf347244c9b50208a3b63a70dd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ea6bc7e91240460e9e366921fc4a68f8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f7687706375441b49b5286f60183efa1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f834ec3ced2b4e3ea429003d436dc691": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "faf57723768b48b99a2ff547099e5a52": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
