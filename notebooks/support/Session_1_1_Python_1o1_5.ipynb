{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python scikit-learn\n",
    "\n",
    "scikit-learn is a popular machine learning library offering a wide range of tools for predictive modeling: classification, regression, clustering, and more.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Basic Concepts](#basic)\n",
    "2. [Advanced Concepts](#advanced)\n",
    "3. [Exercises](#exercises)\n",
    "4. [Real-World Applications](#applications)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Concepts <a name=\"basic\"></a>\n",
    "\n",
    "### 1.1 Classifiers\n",
    "Most scikit-learn APIs follow the `fit` and `predict` pattern."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Example dataset (XOR-like)\n",
    "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "y = np.array([0,1,1,0])\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "preds = model.predict(X)\n",
    "print(\"Predictions:\", preds)\n",
    "print(\"Accuracy:\", accuracy_score(y, preds))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Regression"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Simple regression example\n",
    "X_reg = np.array([[1],[2],[3],[4],[5]])  # features\n",
    "y_reg = np.array([2,4,5,4,5])  # targets\n",
    "\n",
    "reg_model = LinearRegression()\n",
    "reg_model.fit(X_reg, y_reg)\n",
    "\n",
    "print(\"Coefficients:\", reg_model.coef_)\n",
    "print(\"Intercept:\", reg_model.intercept_)\n",
    "\n",
    "y_pred = reg_model.predict(X_reg)\n",
    "print(\"Predictions:\", y_pred)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Advanced Concepts <a name=\"advanced\"></a>\n",
    "\n",
    "### 2.1 Pipelines\n",
    "A pipeline chains multiple transformations and a final estimator."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"svc\", SVC(kernel=\"linear\"))\n",
    "])\n",
    "\n",
    "# Synthetic data\n",
    "X2 = np.array([[1, 200],[2, 180],[3, 240],[4, 210]])\n",
    "y2 = np.array([0,0,1,1])\n",
    "\n",
    "pipeline.fit(X2, y2)\n",
    "pred2 = pipeline.predict(X2)\n",
    "pred2"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Model Selection and Cross-Validation\n",
    "scikit-learn provides utilities for hyperparameter tuning, like `GridSearchCV` or `RandomizedSearchCV`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    \"svc__C\": [0.1, 1, 10],\n",
    "    \"svc__kernel\": [\"linear\", \"rbf\"]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=2)\n",
    "grid_search.fit(X2, y2)\n",
    "print(\"Best Params:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Feature Engineering\n",
    "Feature engineering transforms raw data into features suitable for model training. scikit-learn has classes like `PolynomialFeatures`, `CountVectorizer` (for text), etc."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "X_poly = np.array([[2],[3],[4]])\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_transformed = poly.fit_transform(X_poly)\n",
    "print(\"Original:\", X_poly)\n",
    "print(\"Polynomial Features:\\n\", X_transformed)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Common Metrics\n",
    "In addition to accuracy, scikit-learn offers `precision_score`, `recall_score`, `f1_score`, `r2_score`, etc."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "y_true = [0, 1, 1, 0]\n",
    "y_pred = [0, 1, 0, 0]\n",
    "\n",
    "print(\"Precision:\", precision_score(y_true, y_pred))\n",
    "print(\"Recall:   \", recall_score(y_true, y_pred))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exercises <a name=\"exercises\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Classification\n",
    "1. Use any small dataset (or generate synthetic data) for a classification task.\n",
    "2. Train a logistic regression model.\n",
    "3. Print accuracy."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Your code here\n",
    "X_test = np.array([[...], [...], ...])\n",
    "y_test = np.array([...])\n",
    "# logistic_model = LogisticRegression()\n",
    "# logistic_model.fit(X_test, y_test)\n",
    "# preds_test = logistic_model.predict(X_test)\n",
    "# print(accuracy_score(y_test, preds_test))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Pipeline\n",
    "1. Create a pipeline with a `StandardScaler` and a `KNeighborsClassifier`.\n",
    "2. Fit it on some toy dataset.\n",
    "3. Predict and evaluate the performance."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Your code here\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Grid Search\n",
    "1. Use `GridSearchCV` on any model of your choice (e.g., `SVC`).\n",
    "2. Print the best parameters and best score."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Your code here\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Real-World Applications <a name=\"applications\"></a>\n",
    "\n",
    "### Classification Tasks\n",
    "- **Spam Detection**: Email text classification.\n",
    "- **Image Recognition**: Digits dataset or complex images.\n",
    "\n",
    "### Regression Tasks\n",
    "- **House Price Prediction**: Predicting real estate prices based on features.\n",
    "- **Stock Forecasting**: Although more advanced time-series methods exist, scikit-learn can handle simple regression or feature-based approaches.\n",
    "\n",
    "### Clustering\n",
    "- **Customer Segmentation**: Using KMeans or DBSCAN to group similar customers.\n",
    "\n",
    "### Model Deployment\n",
    "- scikit-learn models can be saved (e.g., `joblib`) and deployed within web applications for real-time inference.\n",
    "\n",
    "scikit-learnâ€™s consistent API and wide range of algorithms make it a go-to toolkit for ML in Python."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
